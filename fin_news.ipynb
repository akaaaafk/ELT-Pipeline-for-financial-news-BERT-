{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-23T22:24:51.304265Z",
     "start_time": "2025-11-23T22:24:51.237558Z"
    }
   },
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Set Java 17 as the Java version for PySpark\n",
    "# PySpark 3.5.7 requires Java 17, can't do with Java 25\n",
    "os.environ['JAVA HOME'] = '/Program Files/Eclipse Adoptium/jdk-17.0.17.10-hotspot'\n",
    "os.environ['PATH'] = os.environ['JAVA_HOME'] + '/bin;' + os.environ['PATH']\n",
    "\n",
    "# Verify Java version\n",
    "import subprocess\n",
    "result = subprocess.run(['java','-version'], capture_output = True,text=True)\n",
    "print(\"Java version:\", result.stderr.split('\\n')[0])\n",
    "\n",
    "# Set Python executable for PySpark\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Java version: openjdk version \"17.0.17\" 2025-10-21\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T22:24:51.320260Z",
     "start_time": "2025-11-23T22:24:51.309016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ],
   "id": "23feab7dc2345c1b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T22:41:36.616494Z",
     "start_time": "2025-11-23T22:41:36.597642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "print(\"HADOOP_HOME =\", os.environ.get(\"HADOOP_HOME\"))\n",
    "\n",
    "if os.environ.get(\"HADOOP_HOME\"):\n",
    "    path = os.path.join(os.environ[\"HADOOP_HOME\"], \"bin\", \"winutils.exe\")\n",
    "    print(\"winutils exists:\", os.path.exists(path), \"->\", path)\n",
    "else:\n",
    "    print(\"❌ Hadoop not configured in this session\")"
   ],
   "id": "fad8faa654efdb30",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HADOOP_HOME = D:\\Code\\hadoop-3.4.0\\hadoop-3.4.0\n",
      "winutils exists: True -> D:\\Code\\hadoop-3.4.0\\hadoop-3.4.0\\bin\\winutils.exe\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T22:24:51.366335Z",
     "start_time": "2025-11-23T22:24:51.341883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"5400-elt-pipeline-test\")\n",
    "    .master(\"local[*]\")\n",
    "    # 可选的防踩坑配置\n",
    "    .config(\"spark.sql.warehouse.dir\", \"file:/D:/tmp/spark-warehouse\")\n",
    "    .config(\"spark.driver.extraJavaOptions\", \"-Duser.timezone=UTC\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "print(\"Spark version:\", spark.version)\n",
    "print(\"SparkContext stopped?\", spark.sparkContext._jsc.sc().isStopped())\n"
   ],
   "id": "ad2fb7fcfcbee547",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 3.5.7\n",
      "SparkContext stopped? False\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T22:24:51.382347Z",
     "start_time": "2025-11-23T22:24:51.370969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"PySpark in venv\") \\\n",
    "    .config(\"spark.cores.max\", \"4\") \\\n",
    "    .config('spark.executor.memory', '8G') \\\n",
    "    .config('spark.driver.maxResultSize', '8g') \\\n",
    "    .config('spark.kryoserializer.buffer.max','512m') \\\n",
    "    .config(\"spark.driver.cores\", \"4\") \\\n",
    "    .config(\"spark.pyspark.python\", sys.executable)\\\n",
    "    .config(\"spark.pyspark.driver.python\", sys.executable)\\\n",
    "    .config(\"spark.python.use.daemon\", \"false\") \\\n",
    "    .config(\"spark.python.worker.reuse\", \"false\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext  # SparkContext对象\n",
    "\n",
    "print(\"Using Apache Spark Version\", spark.version)\n",
    "print(sys.executable)"
   ],
   "id": "9301802f211280e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apache Spark Version 3.5.7\n",
      "D:\\Columbia\\Fall2025\\5400\\SQL.venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T22:24:54.238731Z",
     "start_time": "2025-11-23T22:24:51.387989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = spark.read.format(\"csv\").options(\n",
    "    header = 'true',\n",
    "    inferschema = 'true',\n",
    "    treatEmptyValuesAsNulls = 'true'\n",
    ").load('All_external.csv')\n",
    "df.printSchema()"
   ],
   "id": "6c4f44565057b2af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Article_title: string (nullable = true)\n",
      " |-- Stock_symbol: string (nullable = true)\n",
      " |-- Url: string (nullable = true)\n",
      " |-- Publisher: string (nullable = true)\n",
      " |-- Author: string (nullable = true)\n",
      " |-- Article: string (nullable = true)\n",
      " |-- Lsa_summary: string (nullable = true)\n",
      " |-- Luhn_summary: string (nullable = true)\n",
      " |-- Textrank_summary: string (nullable = true)\n",
      " |-- Lexrank_summary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T22:24:55.659079Z",
     "start_time": "2025-11-23T22:24:54.248310Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"Count of all records:\", df.count())",
   "id": "88c2d8002b9568f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of all records: 29984720\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T22:24:55.689258Z",
     "start_time": "2025-11-23T22:24:55.664024Z"
    }
   },
   "cell_type": "code",
   "source": "df.columns",
   "id": "aed8808a579ee7cd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date',\n",
       " 'Article_title',\n",
       " 'Stock_symbol',\n",
       " 'Url',\n",
       " 'Publisher',\n",
       " 'Author',\n",
       " 'Article',\n",
       " 'Lsa_summary',\n",
       " 'Luhn_summary',\n",
       " 'Textrank_summary',\n",
       " 'Lexrank_summary']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Bronze Layer",
   "id": "4f63aae9ec7e54e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T22:25:47.547169Z",
     "start_time": "2025-11-23T22:25:45.445523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# -------------------------\n",
    "# 1. Spark 这边：Bronze 层\n",
    "# -------------------------\n",
    "# 假设 df 就是你 Bronze 层要保存的 DataFrame\n",
    "news_bronze = df\n",
    "\n",
    "# 可选：减少分区数，避免小文件太多（不是必须）\n",
    "news_bronze = news_bronze.coalesce(4)\n",
    "\n",
    "print(\"Spark rows:\", news_bronze.count())\n",
    "news_bronze.printSchema()\n",
    "\n",
    "# -------------------------\n",
    "# 2. 连接 Docker 里的 Mongo\n",
    "# -------------------------\n",
    "client = MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client[\"news_elt\"]          # 数据库名称你可以自定义\n",
    "bronze_col = db[\"fnspid_bronze\"] # collection 名称\n",
    "\n",
    "# 覆盖写：先清空\n",
    "bronze_col.delete_many({})\n",
    "\n",
    "# -------------------------\n",
    "# 3. 流式写入 Mongo（不走 toPandas）\n",
    "# -------------------------\n",
    "# 注意：这里用 toLocalIterator()，会一批批拉数据，不会一次性塞满内存\n",
    "count = 0\n",
    "for row in news_bronze.toLocalIterator():\n",
    "    doc = row.asDict(recursive=True)  # Row -> dict\n",
    "    bronze_col.insert_one(doc)\n",
    "    count += 1\n",
    "    if count % 10000 == 0:\n",
    "        print(\"已写入\", count, \"条...\")\n",
    "\n",
    "print(\"✅ Mongo Bronze 写入完成，总行数：\", count)\n",
    "\n",
    "# -------------------------\n",
    "# 4. 验证 Mongo 里数据\n",
    "# -------------------------\n",
    "print(\"Mongo rows:\", bronze_col.count_documents({}))\n",
    "print(\"示例文档：\", bronze_col.find_one())\n"
   ],
   "id": "c9547d2d68ce9199",
   "outputs": [
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[WinError 10061] 由于目标计算机积极拒绝，无法连接。",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mConnectionRefusedError\u001B[0m                    Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 11\u001B[0m\n\u001B[0;32m      8\u001B[0m news_bronze \u001B[38;5;241m=\u001B[39m df\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# 可选：减少分区数，避免小文件太多（不是必须）\u001B[39;00m\n\u001B[1;32m---> 11\u001B[0m news_bronze \u001B[38;5;241m=\u001B[39m \u001B[43mnews_bronze\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcoalesce\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSpark rows:\u001B[39m\u001B[38;5;124m\"\u001B[39m, news_bronze\u001B[38;5;241m.\u001B[39mcount())\n\u001B[0;32m     14\u001B[0m news_bronze\u001B[38;5;241m.\u001B[39mprintSchema()\n",
      "File \u001B[1;32mD:\\Columbia\\Fall2025\\5400\\SQL.venv\\lib\\site-packages\\pyspark\\sql\\dataframe.py:1686\u001B[0m, in \u001B[0;36mDataFrame.coalesce\u001B[1;34m(self, numPartitions)\u001B[0m\n\u001B[0;32m   1649\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcoalesce\u001B[39m(\u001B[38;5;28mself\u001B[39m, numPartitions: \u001B[38;5;28mint\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   1650\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1651\u001B[0m \u001B[38;5;124;03m    Returns a new :class:`DataFrame` that has exactly `numPartitions` partitions.\u001B[39;00m\n\u001B[0;32m   1652\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1684\u001B[0m \u001B[38;5;124;03m    1\u001B[39;00m\n\u001B[0;32m   1685\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1686\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcoalesce\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnumPartitions\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
      "File \u001B[1;32mD:\\Columbia\\Fall2025\\5400\\SQL.venv\\lib\\site-packages\\py4j\\java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[1;34m(self, *args)\u001B[0m\n\u001B[0;32m   1314\u001B[0m args_command, temp_args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_args(\u001B[38;5;241m*\u001B[39margs)\n\u001B[0;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[0;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[0;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[0;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m-> 1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend_command\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcommand\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m get_return_value(\n\u001B[0;32m   1323\u001B[0m     answer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n\u001B[0;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
      "File \u001B[1;32mD:\\Columbia\\Fall2025\\5400\\SQL.venv\\lib\\site-packages\\py4j\\java_gateway.py:1036\u001B[0m, in \u001B[0;36mGatewayClient.send_command\u001B[1;34m(self, command, retry, binary)\u001B[0m\n\u001B[0;32m   1015\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21msend_command\u001B[39m(\u001B[38;5;28mself\u001B[39m, command, retry\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, binary\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m   1016\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Sends a command to the JVM. This method is not intended to be\u001B[39;00m\n\u001B[0;32m   1017\u001B[0m \u001B[38;5;124;03m       called directly by Py4J users. It is usually called by\u001B[39;00m\n\u001B[0;32m   1018\u001B[0m \u001B[38;5;124;03m       :class:`JavaMember` instances.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1034\u001B[0m \u001B[38;5;124;03m     if `binary` is `True`.\u001B[39;00m\n\u001B[0;32m   1035\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1036\u001B[0m     connection \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_connection\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1037\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1038\u001B[0m         response \u001B[38;5;241m=\u001B[39m connection\u001B[38;5;241m.\u001B[39msend_command(command)\n",
      "File \u001B[1;32mD:\\Columbia\\Fall2025\\5400\\SQL.venv\\lib\\site-packages\\py4j\\clientserver.py:284\u001B[0m, in \u001B[0;36mJavaClient._get_connection\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    281\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m    283\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m connection \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m connection\u001B[38;5;241m.\u001B[39msocket \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 284\u001B[0m     connection \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_new_connection\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    285\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m connection\n",
      "File \u001B[1;32mD:\\Columbia\\Fall2025\\5400\\SQL.venv\\lib\\site-packages\\py4j\\clientserver.py:291\u001B[0m, in \u001B[0;36mJavaClient._create_new_connection\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    287\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_create_new_connection\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    288\u001B[0m     connection \u001B[38;5;241m=\u001B[39m ClientServerConnection(\n\u001B[0;32m    289\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjava_parameters, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpython_parameters,\n\u001B[0;32m    290\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_property, \u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m--> 291\u001B[0m     \u001B[43mconnection\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect_to_java_server\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    292\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_thread_connection(connection)\n\u001B[0;32m    293\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m connection\n",
      "File \u001B[1;32mD:\\Columbia\\Fall2025\\5400\\SQL.venv\\lib\\site-packages\\py4j\\clientserver.py:438\u001B[0m, in \u001B[0;36mClientServerConnection.connect_to_java_server\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    435\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mssl_context:\n\u001B[0;32m    436\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msocket \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mssl_context\u001B[38;5;241m.\u001B[39mwrap_socket(\n\u001B[0;32m    437\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msocket, server_hostname\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjava_address)\n\u001B[1;32m--> 438\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msocket\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjava_address\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjava_port\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    439\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msocket\u001B[38;5;241m.\u001B[39mmakefile(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    440\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_connected \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[1;31mConnectionRefusedError\u001B[0m: [WinError 10061] 由于目标计算机积极拒绝，无法连接。"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "edf4fed6d279fa6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
