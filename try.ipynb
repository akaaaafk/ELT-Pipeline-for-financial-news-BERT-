{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T23:25:53.456475Z",
     "start_time": "2025-11-23T23:25:44.463419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "csv_path = r\"D:\\Columbia\\Fall2025\\5400\\project\\All_external.csv\"\n",
    "\n",
    "df = (\n",
    "    spark.read\n",
    "    .format(\"csv\")\n",
    "    .options(\n",
    "        header='true',\n",
    "        inferSchema='true',\n",
    "        treatEmptyValuesAsNulls='true'\n",
    "    )\n",
    "    .load(csv_path)\n",
    ")\n",
    "\n",
    "df.printSchema()\n",
    "print(\"Count of all records:\", df.count())\n",
    "print(df.columns)\n"
   ],
   "id": "d854373ace2d7826",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Article_title: string (nullable = true)\n",
      " |-- Stock_symbol: string (nullable = true)\n",
      " |-- Url: string (nullable = true)\n",
      " |-- Publisher: string (nullable = true)\n",
      " |-- Author: string (nullable = true)\n",
      " |-- Article: string (nullable = true)\n",
      " |-- Lsa_summary: string (nullable = true)\n",
      " |-- Luhn_summary: string (nullable = true)\n",
      " |-- Textrank_summary: string (nullable = true)\n",
      " |-- Lexrank_summary: string (nullable = true)\n",
      "\n",
      "Count of all records: 29984720\n",
      "['Date', 'Article_title', 'Stock_symbol', 'Url', 'Publisher', 'Author', 'Article', 'Lsa_summary', 'Luhn_summary', 'Textrank_summary', 'Lexrank_summary']\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Bronze Layer",
   "id": "4f63aae9ec7e54e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T02:50:27.595959Z",
     "start_time": "2025-11-24T02:50:03.303191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql import SparkSession, Row\n",
    "import os\n",
    "\n",
    "# 初始化 SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TestParquet\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Spark alive?\", spark.sparkContext._jsc.sc().isStopped() == False)\n",
    "\n",
    "test_df = spark.createDataFrame([\n",
    "    Row(id=1, txt=\"hello\"),\n",
    "    Row(id=2, txt=\"world\")\n",
    "])\n",
    "\n",
    "test_path = r\"D:\\Columbia\\Fall2025\\5400\\project\\test_parquet\"\n",
    "\n",
    "# 如果文件夹存在先删除\n",
    "if os.path.exists(test_path):\n",
    "    import shutil\n",
    "    shutil.rmtree(test_path)\n",
    "\n",
    "(\n",
    "    test_df\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .parquet(test_path)\n",
    ")\n",
    "\n",
    "print(\"Write OK:\", os.path.exists(test_path))\n",
    "\n",
    "spark.read.parquet(test_path).show()"
   ],
   "id": "ca0b159b4e28950b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark alive? True\n",
      "Write OK: True\n",
      "+---+-----+\n",
      "| id|  txt|\n",
      "+---+-----+\n",
      "|  1|hello|\n",
      "|  2|world|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T02:58:07.397901Z",
     "start_time": "2025-11-24T02:56:05.706320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# ================\n",
    "# 1. 强化版 SparkSession\n",
    "# ================\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "        .appName(\"5400-news-bronze\")\n",
    "        .master(\"local[*]\")\n",
    "        .config(\"spark.driver.memory\", \"8g\")         # 至少 8GB\n",
    "        .config(\"spark.executor.memory\", \"8g\")       # local 模式 = driver\n",
    "        .config(\"spark.sql.shuffle.partitions\", \"200\")   # 提高并行度\n",
    "        .config(\"spark.default.parallelism\", \"200\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "\n",
    "print(\"Spark OK:\", spark.version)\n",
    "\n",
    "# ================\n",
    "# 2. 读取 CSV\n",
    "# ================\n",
    "csv_path = r\"D:\\Columbia\\Fall2025\\5400\\project\\All_external.csv\"\n",
    "\n",
    "df = (\n",
    "    spark.read\n",
    "        .format(\"csv\")\n",
    "        .options(\n",
    "            header='true',\n",
    "            inferSchema='true',\n",
    "            treatEmptyValuesAsNulls='true'\n",
    "        )\n",
    "        .load(csv_path)\n",
    ")\n",
    "\n",
    "print(\"CSV rows:\", df.count())\n",
    "\n",
    "# ================\n",
    "# 3. Bronze 分层路径\n",
    "# ================\n",
    "base_dir = r\"D:\\Columbia\\Fall2025\\5400\\project\\layer\"\n",
    "bronze_path = os.path.join(base_dir, \"bronze\")\n",
    "\n",
    "os.makedirs(bronze_path, exist_ok=True)\n",
    "\n",
    "# ================\n",
    "# 4. repartition 200 → 避免 OOM\n",
    "# ================\n",
    "df_re = df.repartition(200)\n",
    "\n",
    "# ================\n",
    "# 5. 写 parquet（不会挂）\n",
    "# ================\n",
    "(\n",
    "    df_re.write\n",
    "        .mode(\"overwrite\")\n",
    "        .parquet(bronze_path)\n",
    ")\n",
    "\n",
    "print(\"✅ Bronze 层写入完成 →\", bronze_path)\n"
   ],
   "id": "edf4fed6d279fa6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark OK: 3.3.1\n",
      "CSV rows: 29984720\n",
      "✅ Bronze 层写入完成 → D:\\Columbia\\Fall2025\\5400\\project\\layer\\bronze\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T02:59:54.967186Z",
     "start_time": "2025-11-24T02:59:54.949826Z"
    }
   },
   "cell_type": "code",
   "source": "df.printSchema()",
   "id": "ba7d39bef4d02ffd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Article_title: string (nullable = true)\n",
      " |-- Stock_symbol: string (nullable = true)\n",
      " |-- Url: string (nullable = true)\n",
      " |-- Publisher: string (nullable = true)\n",
      " |-- Author: string (nullable = true)\n",
      " |-- Article: string (nullable = true)\n",
      " |-- Lsa_summary: string (nullable = true)\n",
      " |-- Luhn_summary: string (nullable = true)\n",
      " |-- Textrank_summary: string (nullable = true)\n",
      " |-- Lexrank_summary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Silver\n",
   "id": "8132f340f464d8fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "silver_path = os.path.join(base_layer_dir, \"silver\")\n",
    "\n",
    "news_silver = (\n",
    "    news_bronze\n",
    "    # 统一日期格式：Date -> date（DateType）\n",
    "    .withColumn(\"date\", F.to_date(F.col(\"Date\")))\n",
    "    # 股票代码规范化：去空格 + 大写\n",
    "    .withColumn(\"stock_symbol\", F.upper(F.trim(F.col(\"Stock_symbol\"))))\n",
    "    # 正文清洗\n",
    "    .withColumn(\"article_clean\", F.trim(F.col(\"Article\")))\n",
    "    .filter(F.col(\"article_clean\").isNotNull() & (F.col(\"article_clean\") != \"\"))\n",
    "    # 按 Url 去重（你也可以换成其他组合）\n",
    "    .dropDuplicates([\"Url\"])\n",
    "    .select(\n",
    "        \"date\",\n",
    "        \"Article_title\",\n",
    "        \"stock_symbol\",\n",
    "        \"Url\",\n",
    "        \"Publisher\",\n",
    "        \"Author\",\n",
    "        \"article_clean\",\n",
    "        \"Lsa_summary\",\n",
    "        \"Luhn_summary\",\n",
    "        \"Textrank_summary\",\n",
    "        \"Lexrank_summary\"\n",
    "    )\n",
    ")\n",
    "\n",
    "(\n",
    "    news_silver.write\n",
    "    .mode(\"overwrite\")\n",
    "    .parquet(silver_path)\n",
    ")\n",
    "\n",
    "print(\"✅ Silver 层写入完成：\", silver_path)\n",
    "news_silver.show(5, truncate=False)\n"
   ],
   "id": "64bd9c7bae23ac77"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
