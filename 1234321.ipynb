{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-28T04:15:06.842276Z",
     "start_time": "2025-11-28T04:15:06.616130Z"
    }
   },
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# ⭐ 关键更新: 适用于 Spark 3.3.x 和 Scala 2.12 的 Snowflake Connector\n",
    "SNOWFLAKE_CONNECTOR_PACKAGE = \"net.snowflake:spark-snowflake_2.12:2.11.0-spark_3.3\"\n",
    "# 注：如果遇到问题，您可以尝试更新版本，例如 2.12.0 或更高版本。\n",
    "\n",
    "def create_spark(app_name=\"5400-news-elt-snowflake\"):\n",
    "    spark = (\n",
    "        SparkSession.builder\n",
    "        .appName(app_name)\n",
    "        .master(\"local[*]\")\n",
    "        .config(\"spark.driver.memory\", \"12g\")\n",
    "        .config(\"spark.executor.memory\", \"12g\")\n",
    "        .config(\"spark.sql.shuffle.partitions\", \"400\")\n",
    "        .config(\"spark.default.parallelism\", \"400\")\n",
    "        .config(\"spark.sql.parquet.compression.codec\", \"snappy\")\n",
    "        .config(\"spark.hadoop.fs.file.impl\", \"org.apache.hadoop.fs.RawLocalFileSystem\")\n",
    "        .config(\"spark.hadoop.fs.file.impl.disable.cache\", \"true\")\n",
    "        # ⭐ 确保依赖正确\n",
    "        .config(\"spark.jars.packages\", SNOWFLAKE_CONNECTOR_PACKAGE)\n",
    "        .getOrCreate()\n",
    "    )\n",
    "    spark.sparkContext.setLogLevel(\"WARN\")\n",
    "    return spark"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T04:15:09.052413Z",
     "start_time": "2025-11-28T04:15:09.045419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------------------------------------------------------------------------\n",
    "# Snowflake 连接配置 (必须替换为您的真实信息！)\n",
    "# -------------------------------------------------------------------------\n",
    "SNOWFLAKE_OPTIONS = {\n",
    "    \"sfURL\": \"pobriux-fyc84817.snowflakecomputing.com\",\n",
    "    \"sfUser\": \"AKAAAAFK\",\n",
    "    \"sfAuthenticator\": \"externalbrowser\",\n",
    "    \"sfRole\": \"ACCOUNTADMIN\",\n",
    "    \"sfWarehouse\": \"SNOWFLAKE_LEARNING_WH\",\n",
    "    \"sfDatabase\": \"SNOWFLAKE_LEARNING_DB\",\n",
    "    \"sfSchema\": \"PUBLIC\",\n",
    "}\n",
    "\n",
    "\n",
    "def save_to_snowflake(df, table_name, mode=\"overwrite\"):\n",
    "    \"\"\"\n",
    "    使用 Spark Connector 将 DataFrame 写入 Snowflake\n",
    "    \"\"\"\n",
    "    print(f\"❄️ 正在尝试将数据写入 Snowflake 表: {table_name}...\")\n",
    "\n",
    "    try:\n",
    "        # 使用 .format(\"net.snowflake.spark.snowflake\") 调用连接器\n",
    "        (\n",
    "            df.write\n",
    "            .format(\"net.snowflake.spark.snowflake\")\n",
    "            .options(**SNOWFLAKE_OPTIONS) # 传入连接配置\n",
    "            .option(\"dbtable\", table_name) # 目标表名\n",
    "            .mode(mode)\n",
    "            .save()\n",
    "        )\n",
    "        print(f\"✅ 数据已成功写入 Snowflake 表: {table_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Snowflake 写入失败。请检查您的凭证、账号URL和网络连接。\")\n",
    "        print(f\"错误详情: {e}\")"
   ],
   "id": "688cb0120a96e175",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T01:12:02.346172Z",
     "start_time": "2025-11-28T01:12:02.334181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "\n",
    "BASE = r\"D:\\Columbia\\Fall2025\\5400\\project\\layer\"\n",
    "CSV_PATH = r\"D:\\Columbia\\Fall2025\\5400\\project\\All_external.csv\"\n",
    "\n",
    "BRONZE = os.path.join(BASE, \"bronze\")\n",
    "SILVER = os.path.join(BASE, \"silver\")\n",
    "GOLD = os.path.join(BASE, \"gold\")\n",
    "NLP_SILVER = os.path.join(BASE, \"silver_for_nlp\")\n",
    "# 路径定义\n",
    "BASE = r\"D:\\Columbia\\Fall2025\\5400\\project\\layer\"\n",
    "CSV_PATH = r\"D:\\Columbia\\Fall2025\\5400\\project\\All_external.csv\"\n",
    "\n",
    "BRONZE = os.path.join(BASE, \"bronze\")\n",
    "SILVER = os.path.join(BASE, \"silver\")\n",
    "GOLD = os.path.join(BASE, \"gold\")\n",
    "NLP_SILVER = os.path.join(BASE, \"silver_for_nlp\")\n",
    "SENTIMENT_OUTPUT = os.path.join(BASE, \"sentiment_output\") # 对应流程图中的 sentiment.parquet → S3 NLP Zone\n",
    "FACT_NEWS_SENTIMENT = os.path.join(BASE, \"fact_news_sentiment\") # 对应流程图中的 FACT_NEWS_SENTIMENT → Snowflake"
   ],
   "id": "342a63407d569ec9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T01:12:04.226137Z",
     "start_time": "2025-11-28T01:12:04.206835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_bronze(spark):\n",
    "    os.makedirs(BRONZE, exist_ok=True)\n",
    "\n",
    "    print(\"📥 Loading CSV...\")\n",
    "    df = (\n",
    "        spark.read.format(\"csv\")\n",
    "        .options(\n",
    "            header=\"true\",\n",
    "            inferSchema=\"true\",\n",
    "            multiLine=\"true\",\n",
    "            escape=\"\\\"\",\n",
    "            quote=\"\\\"\",\n",
    "            mode=\"PERMISSIVE\"\n",
    "        )\n",
    "        .load(CSV_PATH)\n",
    "    )\n",
    "\n",
    "    # Cleaning string columns\n",
    "    for c, t in df.dtypes:\n",
    "        if t == \"string\":\n",
    "            df = df.withColumn(c, F.trim(F.col(c)))\n",
    "\n",
    "    # date\n",
    "    if \"Date\" in df.columns:\n",
    "        df = df.withColumn(\"Date\", F.to_date(\"Date\", \"yyyy-MM-dd\"))\n",
    "\n",
    "    df = df.repartition(400)\n",
    "\n",
    "    print(\"💾 Writing Bronze...\")\n",
    "    df.write.mode(\"overwrite\").parquet(BRONZE)\n",
    "    print(\"🥉 Bronze Ready:\", BRONZE)\n",
    "\n",
    "    return df\n",
    "\n",
    "def build_silver(spark):\n",
    "    os.makedirs(SILVER, exist_ok=True)\n",
    "    df = spark.read.parquet(BRONZE)\n",
    "\n",
    "    # key fields not null\n",
    "    if \"Date\" in df.columns:\n",
    "        df = df.filter(F.col(\"Date\").isNotNull())\n",
    "    if \"Stock_symbol\" in df.columns:\n",
    "        df = df.filter(F.col(\"Stock_symbol\").isNotNull())\n",
    "\n",
    "    # drop duplicates\n",
    "    df = df.dropDuplicates()\n",
    "\n",
    "    # standardize text fields\n",
    "    if \"Publisher\" in df.columns:\n",
    "        df = df.withColumn(\"Publisher_norm\", F.upper(\"Publisher\"))\n",
    "    if \"Author\" in df.columns:\n",
    "        df = df.withColumn(\"Author_norm\", F.upper(\"Author\"))\n",
    "\n",
    "    # unique ID\n",
    "    df = df.withColumn(\"news_id\", F.monotonically_increasing_id())\n",
    "\n",
    "    # repartition\n",
    "    df = df.repartition(400, \"Stock_symbol\", \"Date\")\n",
    "\n",
    "    print(\"💾 Writing Silver...\")\n",
    "    df.write.mode(\"overwrite\").parquet(SILVER)\n",
    "    print(\"🥈 Silver Ready:\", SILVER)\n",
    "\n",
    "    return df\n",
    "\n",
    "def build_gold(spark):\n",
    "    os.makedirs(GOLD, exist_ok=True)\n",
    "    df = spark.read.parquet(SILVER)\n",
    "\n",
    "    df = df.withColumn(\"title_len\", F.length(\"Article_title\"))\n",
    "\n",
    "    agg_cols = [\n",
    "        F.count(\"*\").alias(\"article_count\"),\n",
    "        F.countDistinct(\"Publisher\").alias(\"publisher_count\"),\n",
    "        F.avg(\"title_len\").alias(\"avg_title_len\"),\n",
    "    ]\n",
    "\n",
    "    for col in [\"Textrank_summary\", \"Lsa_summary\", \"Luhn_summary\", \"Lexrank_summary\"]:\n",
    "        if col in df.columns:\n",
    "            agg_cols.append(F.first(col, ignorenulls=True).alias(\"sample_summary\"))\n",
    "            break\n",
    "\n",
    "    gold_df = df.groupBy(\"Date\", \"Stock_symbol\").agg(*agg_cols)\n",
    "    gold_df = gold_df.repartition(200, \"Stock_symbol\")\n",
    "\n",
    "    print(\"💾 Writing Gold...\")\n",
    "    gold_df.write.mode(\"overwrite\").parquet(GOLD)\n",
    "    print(\"🥇 Gold Ready:\", GOLD)\n",
    "\n",
    "    return gold_df"
   ],
   "id": "51fa78683dba9a20",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T20:48:13.753985Z",
     "start_time": "2025-11-26T20:48:13.743979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_silver_nlp(spark):\n",
    "    os.makedirs(NLP_SILVER, exist_ok=True)\n",
    "\n",
    "    df = spark.read.parquet(SILVER)\n",
    "\n",
    "    # auto select text column\n",
    "    df = df.withColumn(\n",
    "        \"text\",\n",
    "        F.coalesce(\n",
    "            F.col(\"Article\"),\n",
    "            F.col(\"Textrank_summary\"),\n",
    "            F.col(\"Lsa_summary\"),\n",
    "            F.col(\"Luhn_summary\"),\n",
    "            F.col(\"Lexrank_summary\"),\n",
    "            F.col(\"Article_title\"),   # solve empty text cases\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # filter non-empty text\n",
    "    df = df.filter(F.col(\"text\").isNotNull() & (F.length(F.trim(\"text\")) > 0))\n",
    "\n",
    "    df = df.select(\n",
    "        \"news_id\", \"Date\", \"Article_title\", \"Stock_symbol\",\n",
    "        \"Publisher\", \"Author\", \"Url\", \"text\"\n",
    "    ).repartition(200)\n",
    "\n",
    "    df.write.mode(\"overwrite\").parquet(NLP_SILVER)\n",
    "\n",
    "    print(\"🧠 Silver_for_nlp 生成完成:\", NLP_SILVER)\n",
    "    return df"
   ],
   "id": "427411fb03a8f758",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T20:52:16.359527Z",
     "start_time": "2025-11-26T20:48:15.539691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spark = create_spark()\n",
    "\n",
    "bronze_df = build_bronze(spark)\n",
    "#silver_df = build_silver(spark)\n",
    "#gold_df   = build_gold(spark)\n",
    "#nlp_df    = build_silver_nlp(spark)"
   ],
   "id": "61430e7d2607800",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔥 Spark Ready: 3.3.1\n",
      "📥 Loading CSV...\n",
      "💾 Writing Bronze...\n",
      "🥉 Bronze Ready: D:\\Columbia\\Fall2025\\5400\\project\\layer\\bronze\n",
      "💾 Writing Silver...\n",
      "🥈 Silver Ready: D:\\Columbia\\Fall2025\\5400\\project\\layer\\silver\n",
      "💾 Writing Gold...\n",
      "🥇 Gold Ready: D:\\Columbia\\Fall2025\\5400\\project\\layer\\gold\n",
      "🧠 Silver_for_nlp 生成完成: D:\\Columbia\\Fall2025\\5400\\project\\layer\\silver_for_nlp\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T20:52:42.406791Z",
     "start_time": "2025-11-26T20:52:42.221978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "SILVER = r\"D:\\Columbia\\Fall2025\\5400\\project\\layer\\silver\"\n",
    "\n",
    "df = spark.read.parquet(SILVER)\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "df.printSchema()"
   ],
   "id": "11fb7aa801a4ec90",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'Article_title', 'Stock_symbol', 'Url', 'Publisher', 'Author', 'Article', 'Lsa_summary', 'Luhn_summary', 'Textrank_summary', 'Lexrank_summary', 'Publisher_norm', 'Author_norm', 'news_id']\n",
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Article_title: string (nullable = true)\n",
      " |-- Stock_symbol: string (nullable = true)\n",
      " |-- Url: string (nullable = true)\n",
      " |-- Publisher: string (nullable = true)\n",
      " |-- Author: string (nullable = true)\n",
      " |-- Article: string (nullable = true)\n",
      " |-- Lsa_summary: string (nullable = true)\n",
      " |-- Luhn_summary: string (nullable = true)\n",
      " |-- Textrank_summary: string (nullable = true)\n",
      " |-- Lexrank_summary: string (nullable = true)\n",
      " |-- Publisher_norm: string (nullable = true)\n",
      " |-- Author_norm: string (nullable = true)\n",
      " |-- news_id: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T20:52:55.070515Z",
     "start_time": "2025-11-26T20:52:51.314995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pyarrow.dataset as ds\n",
    "\n",
    "NLP_SILVER = r\"D:\\Columbia\\Fall2025\\5400\\project\\layer\\silver_for_nlp\"\n",
    "d = ds.dataset(NLP_SILVER, format=\"parquet\")\n",
    "\n",
    "print(\"NLP rows:\", d.count_rows())\n",
    "print(\"Schema:\", d.schema)"
   ],
   "id": "8320b75ba6bb1e84",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP rows: 3242351\n",
      "Schema: news_id: int64\n",
      "Date: date32[day]\n",
      "Article_title: string\n",
      "Stock_symbol: string\n",
      "Publisher: string\n",
      "Author: string\n",
      "Url: string\n",
      "text: string\n",
      "-- schema metadata --\n",
      "org.apache.spark.version: '3.3.1'\n",
      "org.apache.spark.sql.parquet.row.metadata: '{\"type\":\"struct\",\"fields\":[{\"' + 517\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### NLP(Silver)\n",
   "id": "73cf861fa2531e26"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T20:54:09.524517Z",
     "start_time": "2025-11-26T20:54:07.630966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "SILVER = r\"D:\\Columbia\\Fall2025\\5400\\project\\layer\\silver\"\n",
    "BRONZE = r\"D:\\Columbia\\Fall2025\\5400\\project\\layer\\bronze\"\n",
    "\n",
    "silver_df = spark.read.parquet(SILVER)\n",
    "bronze_df = spark.read.parquet(BRONZE)\n",
    "\n",
    "print(\"Bronze rows:\", bronze_df.count())\n",
    "print(\"Silver rows:\", silver_df.count())\n",
    "silver_df.select(\"Date\").show(5, False)"
   ],
   "id": "ab7be22e8639a6a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bronze rows: 13057514\n",
      "Silver rows: 3242351\n",
      "+----------+\n",
      "|Date      |\n",
      "+----------+\n",
      "|2014-04-23|\n",
      "|2012-02-15|\n",
      "|2017-04-03|\n",
      "|2017-02-15|\n",
      "|2018-03-13|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T21:24:47.784470Z",
     "start_time": "2025-11-26T20:54:47.816063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# distilbert\n",
    "import os\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "BASE = r\"D:\\Columbia\\Fall2025\\5400\\project\\layer\"\n",
    "NLP_SILVER = os.path.join(BASE, \"silver_for_nlp\")\n",
    "SENTIMENT_SAMPLE = os.path.join(BASE, \"sentiment_sample\")\n",
    "os.makedirs(SENTIMENT_SAMPLE, exist_ok=True)\n",
    "\n",
    "# 1. GPU\n",
    "if torch.cuda.is_available() and torch.cuda.device_count() > 0:\n",
    "    device = 0\n",
    "    print(\"✅ Using GPU device 0 for sentiment.\")\n",
    "else:\n",
    "    device = -1\n",
    "    print(\"⚠ 没有可用 CUDA 设备，使用 CPU。\")\n",
    "\n",
    "# 2. HF pipeline\n",
    "sentiment_pipe = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# 3. prepare dataset\n",
    "dataset = ds.dataset(NLP_SILVER, format=\"parquet\")\n",
    "total_rows = dataset.count_rows()\n",
    "print(\"🧠 NLP total rows:\", total_rows)\n",
    "\n",
    "BATCH_ROWS = 4000        # read 4000 rows at a time from parquet\n",
    "PIPELINE_BATCH = 32      # batch_size\n",
    "MAX_LENGTH = 256\n",
    "MAX_ROWS = 3242351\n",
    "processed_rows = 0\n",
    "\n",
    "batches = dataset.to_batches(batch_size=BATCH_ROWS)\n",
    "\n",
    "for i, batch in enumerate(batches):\n",
    "    if processed_rows >= MAX_ROWS:\n",
    "        print(f\"⚡ 已达到 MAX_ROWS={MAX_ROWS}，提前结束。\")\n",
    "        break\n",
    "\n",
    "    table = pa.Table.from_batches([batch])\n",
    "    pdf = table.to_pandas()\n",
    "\n",
    "    # 只保留有 text 的行\n",
    "    pdf = pdf[pdf[\"text\"].notna() & (pdf[\"text\"].astype(str).str.strip() != \"\")]\n",
    "    if pdf.empty:\n",
    "        continue\n",
    "\n",
    "    texts = pdf[\"text\"].astype(str).tolist()\n",
    "\n",
    "    preds = sentiment_pipe(\n",
    "        texts,\n",
    "        batch_size=PIPELINE_BATCH,\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH,\n",
    "    )\n",
    "\n",
    "    pdf[\"sentiment_label\"] = [p[\"label\"] for p in preds]\n",
    "    pdf[\"sentiment_score\"] = [float(p[\"score\"]) for p in preds]\n",
    "    pdf[\"sentiment_score_signed\"] = pdf[\"sentiment_score\"].where(\n",
    "        pdf[\"sentiment_label\"] == \"POSITIVE\",\n",
    "        -pdf[\"sentiment_score\"],\n",
    "    )\n",
    "\n",
    "    out_pdf = pdf[[\"news_id\", \"sentiment_label\",\n",
    "                   \"sentiment_score\", \"sentiment_score_signed\"]]\n",
    "    out_table = pa.Table.from_pandas(out_pdf, preserve_index=False)\n",
    "\n",
    "    out_file = os.path.join(SENTIMENT_SAMPLE, f\"part-{i:05d}.parquet\")\n",
    "    pq.write_table(out_table, out_file)\n",
    "\n",
    "    processed_rows += len(out_pdf)\n",
    "    print(f\"✅ batch {i}, 当前写出 {len(out_pdf)} 行，累计 {processed_rows} 行\")\n",
    "\n",
    "print(\"🎉 Sentiment SAMPLE 写完:\", SENTIMENT_SAMPLE)\n",
    "print(\"实际处理行数:\", processed_rows)\n"
   ],
   "id": "aade32850f4ef380",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Using GPU device 0 for sentiment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 NLP total rows: 3242351\n",
      "✅ batch 0, 当前写出 4000 行，累计 4000 行\n",
      "✅ batch 1, 当前写出 4000 行，累计 8000 行\n",
      "✅ batch 2, 当前写出 4000 行，累计 12000 行\n",
      "✅ batch 3, 当前写出 4000 行，累计 16000 行\n",
      "✅ batch 4, 当前写出 226 行，累计 16226 行\n",
      "✅ batch 5, 当前写出 4000 行，累计 20226 行\n",
      "✅ batch 6, 当前写出 4000 行，累计 24226 行\n",
      "✅ batch 7, 当前写出 4000 行，累计 28226 行\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ batch 8, 当前写出 4000 行，累计 32226 行\n",
      "✅ batch 9, 当前写出 224 行，累计 32450 行\n",
      "✅ batch 10, 当前写出 4000 行，累计 36450 行\n",
      "✅ batch 11, 当前写出 4000 行，累计 40450 行\n",
      "✅ batch 12, 当前写出 4000 行，累计 44450 行\n",
      "✅ batch 13, 当前写出 4000 行，累计 48450 行\n",
      "✅ batch 14, 当前写出 223 行，累计 48673 行\n",
      "✅ batch 15, 当前写出 4000 行，累计 52673 行\n",
      "✅ batch 16, 当前写出 4000 行，累计 56673 行\n",
      "✅ batch 17, 当前写出 4000 行，累计 60673 行\n",
      "✅ batch 18, 当前写出 4000 行，累计 64673 行\n",
      "✅ batch 19, 当前写出 222 行，累计 64895 行\n",
      "✅ batch 20, 当前写出 4000 行，累计 68895 行\n",
      "✅ batch 21, 当前写出 4000 行，累计 72895 行\n",
      "✅ batch 22, 当前写出 4000 行，累计 76895 行\n",
      "✅ batch 23, 当前写出 4000 行，累计 80895 行\n",
      "✅ batch 24, 当前写出 227 行，累计 81122 行\n",
      "✅ batch 25, 当前写出 4000 行，累计 85122 行\n",
      "✅ batch 26, 当前写出 4000 行，累计 89122 行\n",
      "✅ batch 27, 当前写出 4000 行，累计 93122 行\n",
      "✅ batch 28, 当前写出 4000 行，累计 97122 行\n",
      "✅ batch 29, 当前写出 222 行，累计 97344 行\n",
      "✅ batch 30, 当前写出 4000 行，累计 101344 行\n",
      "✅ batch 31, 当前写出 4000 行，累计 105344 行\n",
      "✅ batch 32, 当前写出 4000 行，累计 109344 行\n",
      "✅ batch 33, 当前写出 4000 行，累计 113344 行\n",
      "✅ batch 34, 当前写出 224 行，累计 113568 行\n",
      "✅ batch 35, 当前写出 4000 行，累计 117568 行\n",
      "✅ batch 36, 当前写出 4000 行，累计 121568 行\n",
      "✅ batch 37, 当前写出 4000 行，累计 125568 行\n",
      "✅ batch 38, 当前写出 4000 行，累计 129568 行\n",
      "✅ batch 39, 当前写出 226 行，累计 129794 行\n",
      "✅ batch 40, 当前写出 4000 行，累计 133794 行\n",
      "✅ batch 41, 当前写出 4000 行，累计 137794 行\n",
      "✅ batch 42, 当前写出 4000 行，累计 141794 行\n",
      "✅ batch 43, 当前写出 4000 行，累计 145794 行\n",
      "✅ batch 44, 当前写出 225 行，累计 146019 行\n",
      "✅ batch 45, 当前写出 4000 行，累计 150019 行\n",
      "✅ batch 46, 当前写出 4000 行，累计 154019 行\n",
      "✅ batch 47, 当前写出 4000 行，累计 158019 行\n",
      "✅ batch 48, 当前写出 4000 行，累计 162019 行\n",
      "✅ batch 49, 当前写出 227 行，累计 162246 行\n",
      "✅ batch 50, 当前写出 4000 行，累计 166246 行\n",
      "✅ batch 51, 当前写出 4000 行，累计 170246 行\n",
      "✅ batch 52, 当前写出 4000 行，累计 174246 行\n",
      "✅ batch 53, 当前写出 4000 行，累计 178246 行\n",
      "✅ batch 54, 当前写出 223 行，累计 178469 行\n",
      "✅ batch 55, 当前写出 4000 行，累计 182469 行\n",
      "✅ batch 56, 当前写出 4000 行，累计 186469 行\n",
      "✅ batch 57, 当前写出 4000 行，累计 190469 行\n",
      "✅ batch 58, 当前写出 4000 行，累计 194469 行\n",
      "✅ batch 59, 当前写出 221 行，累计 194690 行\n",
      "✅ batch 60, 当前写出 4000 行，累计 198690 行\n",
      "✅ batch 61, 当前写出 4000 行，累计 202690 行\n",
      "✅ batch 62, 当前写出 4000 行，累计 206690 行\n",
      "✅ batch 63, 当前写出 4000 行，累计 210690 行\n",
      "✅ batch 64, 当前写出 219 行，累计 210909 行\n",
      "✅ batch 65, 当前写出 4000 行，累计 214909 行\n",
      "✅ batch 66, 当前写出 4000 行，累计 218909 行\n",
      "✅ batch 67, 当前写出 4000 行，累计 222909 行\n",
      "✅ batch 68, 当前写出 4000 行，累计 226909 行\n",
      "✅ batch 69, 当前写出 218 行，累计 227127 行\n",
      "✅ batch 70, 当前写出 4000 行，累计 231127 行\n",
      "✅ batch 71, 当前写出 4000 行，累计 235127 行\n",
      "✅ batch 72, 当前写出 4000 行，累计 239127 行\n",
      "✅ batch 73, 当前写出 4000 行，累计 243127 行\n",
      "✅ batch 74, 当前写出 217 行，累计 243344 行\n",
      "✅ batch 75, 当前写出 4000 行，累计 247344 行\n",
      "✅ batch 76, 当前写出 4000 行，累计 251344 行\n",
      "✅ batch 77, 当前写出 4000 行，累计 255344 行\n",
      "✅ batch 78, 当前写出 4000 行，累计 259344 行\n",
      "✅ batch 79, 当前写出 218 行，累计 259562 行\n",
      "✅ batch 80, 当前写出 4000 行，累计 263562 行\n",
      "✅ batch 81, 当前写出 4000 行，累计 267562 行\n",
      "✅ batch 82, 当前写出 4000 行，累计 271562 行\n",
      "✅ batch 83, 当前写出 4000 行，累计 275562 行\n",
      "✅ batch 84, 当前写出 218 行，累计 275780 行\n",
      "✅ batch 85, 当前写出 4000 行，累计 279780 行\n",
      "✅ batch 86, 当前写出 4000 行，累计 283780 行\n",
      "✅ batch 87, 当前写出 4000 行，累计 287780 行\n",
      "✅ batch 88, 当前写出 4000 行，累计 291780 行\n",
      "✅ batch 89, 当前写出 218 行，累计 291998 行\n",
      "✅ batch 90, 当前写出 4000 行，累计 295998 行\n",
      "✅ batch 91, 当前写出 4000 行，累计 299998 行\n",
      "✅ batch 92, 当前写出 4000 行，累计 303998 行\n",
      "✅ batch 93, 当前写出 4000 行，累计 307998 行\n",
      "✅ batch 94, 当前写出 218 行，累计 308216 行\n",
      "✅ batch 95, 当前写出 4000 行，累计 312216 行\n",
      "✅ batch 96, 当前写出 4000 行，累计 316216 行\n",
      "✅ batch 97, 当前写出 4000 行，累计 320216 行\n",
      "✅ batch 98, 当前写出 4000 行，累计 324216 行\n",
      "✅ batch 99, 当前写出 218 行，累计 324434 行\n",
      "✅ batch 100, 当前写出 4000 行，累计 328434 行\n",
      "✅ batch 101, 当前写出 4000 行，累计 332434 行\n",
      "✅ batch 102, 当前写出 4000 行，累计 336434 行\n",
      "✅ batch 103, 当前写出 4000 行，累计 340434 行\n",
      "✅ batch 104, 当前写出 216 行，累计 340650 行\n",
      "✅ batch 105, 当前写出 4000 行，累计 344650 行\n",
      "✅ batch 106, 当前写出 4000 行，累计 348650 行\n",
      "✅ batch 107, 当前写出 4000 行，累计 352650 行\n",
      "✅ batch 108, 当前写出 4000 行，累计 356650 行\n",
      "✅ batch 109, 当前写出 212 行，累计 356862 行\n",
      "✅ batch 110, 当前写出 4000 行，累计 360862 行\n",
      "✅ batch 111, 当前写出 4000 行，累计 364862 行\n",
      "✅ batch 112, 当前写出 4000 行，累计 368862 行\n",
      "✅ batch 113, 当前写出 4000 行，累计 372862 行\n",
      "✅ batch 114, 当前写出 211 行，累计 373073 行\n",
      "✅ batch 115, 当前写出 4000 行，累计 377073 行\n",
      "✅ batch 116, 当前写出 4000 行，累计 381073 行\n",
      "✅ batch 117, 当前写出 4000 行，累计 385073 行\n",
      "✅ batch 118, 当前写出 4000 行，累计 389073 行\n",
      "✅ batch 119, 当前写出 208 行，累计 389281 行\n",
      "✅ batch 120, 当前写出 4000 行，累计 393281 行\n",
      "✅ batch 121, 当前写出 4000 行，累计 397281 行\n",
      "✅ batch 122, 当前写出 4000 行，累计 401281 行\n",
      "✅ batch 123, 当前写出 4000 行，累计 405281 行\n",
      "✅ batch 124, 当前写出 208 行，累计 405489 行\n",
      "✅ batch 125, 当前写出 4000 行，累计 409489 行\n",
      "✅ batch 126, 当前写出 4000 行，累计 413489 行\n",
      "✅ batch 127, 当前写出 4000 行，累计 417489 行\n",
      "✅ batch 128, 当前写出 4000 行，累计 421489 行\n",
      "✅ batch 129, 当前写出 210 行，累计 421699 行\n",
      "✅ batch 130, 当前写出 4000 行，累计 425699 行\n",
      "✅ batch 131, 当前写出 4000 行，累计 429699 行\n",
      "✅ batch 132, 当前写出 4000 行，累计 433699 行\n",
      "✅ batch 133, 当前写出 4000 行，累计 437699 行\n",
      "✅ batch 134, 当前写出 210 行，累计 437909 行\n",
      "✅ batch 135, 当前写出 4000 行，累计 441909 行\n",
      "✅ batch 136, 当前写出 4000 行，累计 445909 行\n",
      "✅ batch 137, 当前写出 4000 行，累计 449909 行\n",
      "✅ batch 138, 当前写出 4000 行，累计 453909 行\n",
      "✅ batch 139, 当前写出 209 行，累计 454118 行\n",
      "✅ batch 140, 当前写出 4000 行，累计 458118 行\n",
      "✅ batch 141, 当前写出 4000 行，累计 462118 行\n",
      "✅ batch 142, 当前写出 4000 行，累计 466118 行\n",
      "✅ batch 143, 当前写出 4000 行，累计 470118 行\n",
      "✅ batch 144, 当前写出 209 行，累计 470327 行\n",
      "✅ batch 145, 当前写出 4000 行，累计 474327 行\n",
      "✅ batch 146, 当前写出 4000 行，累计 478327 行\n",
      "✅ batch 147, 当前写出 4000 行，累计 482327 行\n",
      "✅ batch 148, 当前写出 4000 行，累计 486327 行\n",
      "✅ batch 149, 当前写出 210 行，累计 486537 行\n",
      "✅ batch 150, 当前写出 4000 行，累计 490537 行\n",
      "✅ batch 151, 当前写出 4000 行，累计 494537 行\n",
      "✅ batch 152, 当前写出 4000 行，累计 498537 行\n",
      "✅ batch 153, 当前写出 4000 行，累计 502537 行\n",
      "✅ batch 154, 当前写出 211 行，累计 502748 行\n",
      "✅ batch 155, 当前写出 4000 行，累计 506748 行\n",
      "✅ batch 156, 当前写出 4000 行，累计 510748 行\n",
      "✅ batch 157, 当前写出 4000 行，累计 514748 行\n",
      "✅ batch 158, 当前写出 4000 行，累计 518748 行\n",
      "✅ batch 159, 当前写出 210 行，累计 518958 行\n",
      "✅ batch 160, 当前写出 4000 行，累计 522958 行\n",
      "✅ batch 161, 当前写出 4000 行，累计 526958 行\n",
      "✅ batch 162, 当前写出 4000 行，累计 530958 行\n",
      "✅ batch 163, 当前写出 4000 行，累计 534958 行\n",
      "✅ batch 164, 当前写出 210 行，累计 535168 行\n",
      "✅ batch 165, 当前写出 4000 行，累计 539168 行\n",
      "✅ batch 166, 当前写出 4000 行，累计 543168 行\n",
      "✅ batch 167, 当前写出 4000 行，累计 547168 行\n",
      "✅ batch 168, 当前写出 4000 行，累计 551168 行\n",
      "✅ batch 169, 当前写出 206 行，累计 551374 行\n",
      "✅ batch 170, 当前写出 4000 行，累计 555374 行\n",
      "✅ batch 171, 当前写出 4000 行，累计 559374 行\n",
      "✅ batch 172, 当前写出 4000 行，累计 563374 行\n",
      "✅ batch 173, 当前写出 4000 行，累计 567374 行\n",
      "✅ batch 174, 当前写出 207 行，累计 567581 行\n",
      "✅ batch 175, 当前写出 4000 行，累计 571581 行\n",
      "✅ batch 176, 当前写出 4000 行，累计 575581 行\n",
      "✅ batch 177, 当前写出 4000 行，累计 579581 行\n",
      "✅ batch 178, 当前写出 4000 行，累计 583581 行\n",
      "✅ batch 179, 当前写出 207 行，累计 583788 行\n",
      "✅ batch 180, 当前写出 4000 行，累计 587788 行\n",
      "✅ batch 181, 当前写出 4000 行，累计 591788 行\n",
      "✅ batch 182, 当前写出 4000 行，累计 595788 行\n",
      "✅ batch 183, 当前写出 4000 行，累计 599788 行\n",
      "✅ batch 184, 当前写出 209 行，累计 599997 行\n",
      "✅ batch 185, 当前写出 4000 行，累计 603997 行\n",
      "✅ batch 186, 当前写出 4000 行，累计 607997 行\n",
      "✅ batch 187, 当前写出 4000 行，累计 611997 行\n",
      "✅ batch 188, 当前写出 4000 行，累计 615997 行\n",
      "✅ batch 189, 当前写出 210 行，累计 616207 行\n",
      "✅ batch 190, 当前写出 4000 行，累计 620207 行\n",
      "✅ batch 191, 当前写出 4000 行，累计 624207 行\n",
      "✅ batch 192, 当前写出 4000 行，累计 628207 行\n",
      "✅ batch 193, 当前写出 4000 行，累计 632207 行\n",
      "✅ batch 194, 当前写出 210 行，累计 632417 行\n",
      "✅ batch 195, 当前写出 4000 行，累计 636417 行\n",
      "✅ batch 196, 当前写出 4000 行，累计 640417 行\n",
      "✅ batch 197, 当前写出 4000 行，累计 644417 行\n",
      "✅ batch 198, 当前写出 4000 行，累计 648417 行\n",
      "✅ batch 199, 当前写出 213 行，累计 648630 行\n",
      "✅ batch 200, 当前写出 4000 行，累计 652630 行\n",
      "✅ batch 201, 当前写出 4000 行，累计 656630 行\n",
      "✅ batch 202, 当前写出 4000 行，累计 660630 行\n",
      "✅ batch 203, 当前写出 4000 行，累计 664630 行\n",
      "✅ batch 204, 当前写出 210 行，累计 664840 行\n",
      "✅ batch 205, 当前写出 4000 行，累计 668840 行\n",
      "✅ batch 206, 当前写出 4000 行，累计 672840 行\n",
      "✅ batch 207, 当前写出 4000 行，累计 676840 行\n",
      "✅ batch 208, 当前写出 4000 行，累计 680840 行\n",
      "✅ batch 209, 当前写出 209 行，累计 681049 行\n",
      "✅ batch 210, 当前写出 4000 行，累计 685049 行\n",
      "✅ batch 211, 当前写出 4000 行，累计 689049 行\n",
      "✅ batch 212, 当前写出 4000 行，累计 693049 行\n",
      "✅ batch 213, 当前写出 4000 行，累计 697049 行\n",
      "✅ batch 214, 当前写出 205 行，累计 697254 行\n",
      "✅ batch 215, 当前写出 4000 行，累计 701254 行\n",
      "✅ batch 216, 当前写出 4000 行，累计 705254 行\n",
      "✅ batch 217, 当前写出 4000 行，累计 709254 行\n",
      "✅ batch 218, 当前写出 4000 行，累计 713254 行\n",
      "✅ batch 219, 当前写出 206 行，累计 713460 行\n",
      "✅ batch 220, 当前写出 4000 行，累计 717460 行\n",
      "✅ batch 221, 当前写出 4000 行，累计 721460 行\n",
      "✅ batch 222, 当前写出 4000 行，累计 725460 行\n",
      "✅ batch 223, 当前写出 4000 行，累计 729460 行\n",
      "✅ batch 224, 当前写出 207 行，累计 729667 行\n",
      "✅ batch 225, 当前写出 4000 行，累计 733667 行\n",
      "✅ batch 226, 当前写出 4000 行，累计 737667 行\n",
      "✅ batch 227, 当前写出 4000 行，累计 741667 行\n",
      "✅ batch 228, 当前写出 4000 行，累计 745667 行\n",
      "✅ batch 229, 当前写出 206 行，累计 745873 行\n",
      "✅ batch 230, 当前写出 4000 行，累计 749873 行\n",
      "✅ batch 231, 当前写出 4000 行，累计 753873 行\n",
      "✅ batch 232, 当前写出 4000 行，累计 757873 行\n",
      "✅ batch 233, 当前写出 4000 行，累计 761873 行\n",
      "✅ batch 234, 当前写出 205 行，累计 762078 行\n",
      "✅ batch 235, 当前写出 4000 行，累计 766078 行\n",
      "✅ batch 236, 当前写出 4000 行，累计 770078 行\n",
      "✅ batch 237, 当前写出 4000 行，累计 774078 行\n",
      "✅ batch 238, 当前写出 4000 行，累计 778078 行\n",
      "✅ batch 239, 当前写出 205 行，累计 778283 行\n",
      "✅ batch 240, 当前写出 4000 行，累计 782283 行\n",
      "✅ batch 241, 当前写出 4000 行，累计 786283 行\n",
      "✅ batch 242, 当前写出 4000 行，累计 790283 行\n",
      "✅ batch 243, 当前写出 4000 行，累计 794283 行\n",
      "✅ batch 244, 当前写出 208 行，累计 794491 行\n",
      "✅ batch 245, 当前写出 4000 行，累计 798491 行\n",
      "✅ batch 246, 当前写出 4000 行，累计 802491 行\n",
      "✅ batch 247, 当前写出 4000 行，累计 806491 行\n",
      "✅ batch 248, 当前写出 4000 行，累计 810491 行\n",
      "✅ batch 249, 当前写出 209 行，累计 810700 行\n",
      "✅ batch 250, 当前写出 4000 行，累计 814700 行\n",
      "✅ batch 251, 当前写出 4000 行，累计 818700 行\n",
      "✅ batch 252, 当前写出 4000 行，累计 822700 行\n",
      "✅ batch 253, 当前写出 4000 行，累计 826700 行\n",
      "✅ batch 254, 当前写出 209 行，累计 826909 行\n",
      "✅ batch 255, 当前写出 4000 行，累计 830909 行\n",
      "✅ batch 256, 当前写出 4000 行，累计 834909 行\n",
      "✅ batch 257, 当前写出 4000 行，累计 838909 行\n",
      "✅ batch 258, 当前写出 4000 行，累计 842909 行\n",
      "✅ batch 259, 当前写出 208 行，累计 843117 行\n",
      "✅ batch 260, 当前写出 4000 行，累计 847117 行\n",
      "✅ batch 261, 当前写出 4000 行，累计 851117 行\n",
      "✅ batch 262, 当前写出 4000 行，累计 855117 行\n",
      "✅ batch 263, 当前写出 4000 行，累计 859117 行\n",
      "✅ batch 264, 当前写出 211 行，累计 859328 行\n",
      "✅ batch 265, 当前写出 4000 行，累计 863328 行\n",
      "✅ batch 266, 当前写出 4000 行，累计 867328 行\n",
      "✅ batch 267, 当前写出 4000 行，累计 871328 行\n",
      "✅ batch 268, 当前写出 4000 行，累计 875328 行\n",
      "✅ batch 269, 当前写出 209 行，累计 875537 行\n",
      "✅ batch 270, 当前写出 4000 行，累计 879537 行\n",
      "✅ batch 271, 当前写出 4000 行，累计 883537 行\n",
      "✅ batch 272, 当前写出 4000 行，累计 887537 行\n",
      "✅ batch 273, 当前写出 4000 行，累计 891537 行\n",
      "✅ batch 274, 当前写出 206 行，累计 891743 行\n",
      "✅ batch 275, 当前写出 4000 行，累计 895743 行\n",
      "✅ batch 276, 当前写出 4000 行，累计 899743 行\n",
      "✅ batch 277, 当前写出 4000 行，累计 903743 行\n",
      "✅ batch 278, 当前写出 4000 行，累计 907743 行\n",
      "✅ batch 279, 当前写出 205 行，累计 907948 行\n",
      "✅ batch 280, 当前写出 4000 行，累计 911948 行\n",
      "✅ batch 281, 当前写出 4000 行，累计 915948 行\n",
      "✅ batch 282, 当前写出 4000 行，累计 919948 行\n",
      "✅ batch 283, 当前写出 4000 行，累计 923948 行\n",
      "✅ batch 284, 当前写出 204 行，累计 924152 行\n",
      "✅ batch 285, 当前写出 4000 行，累计 928152 行\n",
      "✅ batch 286, 当前写出 4000 行，累计 932152 行\n",
      "✅ batch 287, 当前写出 4000 行，累计 936152 行\n",
      "✅ batch 288, 当前写出 4000 行，累计 940152 行\n",
      "✅ batch 289, 当前写出 202 行，累计 940354 行\n",
      "✅ batch 290, 当前写出 4000 行，累计 944354 行\n",
      "✅ batch 291, 当前写出 4000 行，累计 948354 行\n",
      "✅ batch 292, 当前写出 4000 行，累计 952354 行\n",
      "✅ batch 293, 当前写出 4000 行，累计 956354 行\n",
      "✅ batch 294, 当前写出 201 行，累计 956555 行\n",
      "✅ batch 295, 当前写出 4000 行，累计 960555 行\n",
      "✅ batch 296, 当前写出 4000 行，累计 964555 行\n",
      "✅ batch 297, 当前写出 4000 行，累计 968555 行\n",
      "✅ batch 298, 当前写出 4000 行，累计 972555 行\n",
      "✅ batch 299, 当前写出 203 行，累计 972758 行\n",
      "✅ batch 300, 当前写出 4000 行，累计 976758 行\n",
      "✅ batch 301, 当前写出 4000 行，累计 980758 行\n",
      "✅ batch 302, 当前写出 4000 行，累计 984758 行\n",
      "✅ batch 303, 当前写出 4000 行，累计 988758 行\n",
      "✅ batch 304, 当前写出 203 行，累计 988961 行\n",
      "✅ batch 305, 当前写出 4000 行，累计 992961 行\n",
      "✅ batch 306, 当前写出 4000 行，累计 996961 行\n",
      "✅ batch 307, 当前写出 4000 行，累计 1000961 行\n",
      "✅ batch 308, 当前写出 4000 行，累计 1004961 行\n",
      "✅ batch 309, 当前写出 203 行，累计 1005164 行\n",
      "✅ batch 310, 当前写出 4000 行，累计 1009164 行\n",
      "✅ batch 311, 当前写出 4000 行，累计 1013164 行\n",
      "✅ batch 312, 当前写出 4000 行，累计 1017164 行\n",
      "✅ batch 313, 当前写出 4000 行，累计 1021164 行\n",
      "✅ batch 314, 当前写出 199 行，累计 1021363 行\n",
      "✅ batch 315, 当前写出 4000 行，累计 1025363 行\n",
      "✅ batch 316, 当前写出 4000 行，累计 1029363 行\n",
      "✅ batch 317, 当前写出 4000 行，累计 1033363 行\n",
      "✅ batch 318, 当前写出 4000 行，累计 1037363 行\n",
      "✅ batch 319, 当前写出 204 行，累计 1037567 行\n",
      "✅ batch 320, 当前写出 4000 行，累计 1041567 行\n",
      "✅ batch 321, 当前写出 4000 行，累计 1045567 行\n",
      "✅ batch 322, 当前写出 4000 行，累计 1049567 行\n",
      "✅ batch 323, 当前写出 4000 行，累计 1053567 行\n",
      "✅ batch 324, 当前写出 206 行，累计 1053773 行\n",
      "✅ batch 325, 当前写出 4000 行，累计 1057773 行\n",
      "✅ batch 326, 当前写出 4000 行，累计 1061773 行\n",
      "✅ batch 327, 当前写出 4000 行，累计 1065773 行\n",
      "✅ batch 328, 当前写出 4000 行，累计 1069773 行\n",
      "✅ batch 329, 当前写出 207 行，累计 1069980 行\n",
      "✅ batch 330, 当前写出 4000 行，累计 1073980 行\n",
      "✅ batch 331, 当前写出 4000 行，累计 1077980 行\n",
      "✅ batch 332, 当前写出 4000 行，累计 1081980 行\n",
      "✅ batch 333, 当前写出 4000 行，累计 1085980 行\n",
      "✅ batch 334, 当前写出 208 行，累计 1086188 行\n",
      "✅ batch 335, 当前写出 4000 行，累计 1090188 行\n",
      "✅ batch 336, 当前写出 4000 行，累计 1094188 行\n",
      "✅ batch 337, 当前写出 4000 行，累计 1098188 行\n",
      "✅ batch 338, 当前写出 4000 行，累计 1102188 行\n",
      "✅ batch 339, 当前写出 207 行，累计 1102395 行\n",
      "✅ batch 340, 当前写出 4000 行，累计 1106395 行\n",
      "✅ batch 341, 当前写出 4000 行，累计 1110395 行\n",
      "✅ batch 342, 当前写出 4000 行，累计 1114395 行\n",
      "✅ batch 343, 当前写出 4000 行，累计 1118395 行\n",
      "✅ batch 344, 当前写出 205 行，累计 1118600 行\n",
      "✅ batch 345, 当前写出 4000 行，累计 1122600 行\n",
      "✅ batch 346, 当前写出 4000 行，累计 1126600 行\n",
      "✅ batch 347, 当前写出 4000 行，累计 1130600 行\n",
      "✅ batch 348, 当前写出 4000 行，累计 1134600 行\n",
      "✅ batch 349, 当前写出 208 行，累计 1134808 行\n",
      "✅ batch 350, 当前写出 4000 行，累计 1138808 行\n",
      "✅ batch 351, 当前写出 4000 行，累计 1142808 行\n",
      "✅ batch 352, 当前写出 4000 行，累计 1146808 行\n",
      "✅ batch 353, 当前写出 4000 行，累计 1150808 行\n",
      "✅ batch 354, 当前写出 207 行，累计 1151015 行\n",
      "✅ batch 355, 当前写出 4000 行，累计 1155015 行\n",
      "✅ batch 356, 当前写出 4000 行，累计 1159015 行\n",
      "✅ batch 357, 当前写出 4000 行，累计 1163015 行\n",
      "✅ batch 358, 当前写出 4000 行，累计 1167015 行\n",
      "✅ batch 359, 当前写出 208 行，累计 1167223 行\n",
      "✅ batch 360, 当前写出 4000 行，累计 1171223 行\n",
      "✅ batch 361, 当前写出 4000 行，累计 1175223 行\n",
      "✅ batch 362, 当前写出 4000 行，累计 1179223 行\n",
      "✅ batch 363, 当前写出 4000 行，累计 1183223 行\n",
      "✅ batch 364, 当前写出 208 行，累计 1183431 行\n",
      "✅ batch 365, 当前写出 4000 行，累计 1187431 行\n",
      "✅ batch 366, 当前写出 4000 行，累计 1191431 行\n",
      "✅ batch 367, 当前写出 4000 行，累计 1195431 行\n",
      "✅ batch 368, 当前写出 4000 行，累计 1199431 行\n",
      "✅ batch 369, 当前写出 207 行，累计 1199638 行\n",
      "✅ batch 370, 当前写出 4000 行，累计 1203638 行\n",
      "✅ batch 371, 当前写出 4000 行，累计 1207638 行\n",
      "✅ batch 372, 当前写出 4000 行，累计 1211638 行\n",
      "✅ batch 373, 当前写出 4000 行，累计 1215638 行\n",
      "✅ batch 374, 当前写出 210 行，累计 1215848 行\n",
      "✅ batch 375, 当前写出 4000 行，累计 1219848 行\n",
      "✅ batch 376, 当前写出 4000 行，累计 1223848 行\n",
      "✅ batch 377, 当前写出 4000 行，累计 1227848 行\n",
      "✅ batch 378, 当前写出 4000 行，累计 1231848 行\n",
      "✅ batch 379, 当前写出 207 行，累计 1232055 行\n",
      "✅ batch 380, 当前写出 4000 行，累计 1236055 行\n",
      "✅ batch 381, 当前写出 4000 行，累计 1240055 行\n",
      "✅ batch 382, 当前写出 4000 行，累计 1244055 行\n",
      "✅ batch 383, 当前写出 4000 行，累计 1248055 行\n",
      "✅ batch 384, 当前写出 207 行，累计 1248262 行\n",
      "✅ batch 385, 当前写出 4000 行，累计 1252262 行\n",
      "✅ batch 386, 当前写出 4000 行，累计 1256262 行\n",
      "✅ batch 387, 当前写出 4000 行，累计 1260262 行\n",
      "✅ batch 388, 当前写出 4000 行，累计 1264262 行\n",
      "✅ batch 389, 当前写出 214 行，累计 1264476 行\n",
      "✅ batch 390, 当前写出 4000 行，累计 1268476 行\n",
      "✅ batch 391, 当前写出 4000 行，累计 1272476 行\n",
      "✅ batch 392, 当前写出 4000 行，累计 1276476 行\n",
      "✅ batch 393, 当前写出 4000 行，累计 1280476 行\n",
      "✅ batch 394, 当前写出 215 行，累计 1280691 行\n",
      "✅ batch 395, 当前写出 4000 行，累计 1284691 行\n",
      "✅ batch 396, 当前写出 4000 行，累计 1288691 行\n",
      "✅ batch 397, 当前写出 4000 行，累计 1292691 行\n",
      "✅ batch 398, 当前写出 4000 行，累计 1296691 行\n",
      "✅ batch 399, 当前写出 214 行，累计 1296905 行\n",
      "✅ batch 400, 当前写出 4000 行，累计 1300905 行\n",
      "✅ batch 401, 当前写出 4000 行，累计 1304905 行\n",
      "✅ batch 402, 当前写出 4000 行，累计 1308905 行\n",
      "✅ batch 403, 当前写出 4000 行，累计 1312905 行\n",
      "✅ batch 404, 当前写出 215 行，累计 1313120 行\n",
      "✅ batch 405, 当前写出 4000 行，累计 1317120 行\n",
      "✅ batch 406, 当前写出 4000 行，累计 1321120 行\n",
      "✅ batch 407, 当前写出 4000 行，累计 1325120 行\n",
      "✅ batch 408, 当前写出 4000 行，累计 1329120 行\n",
      "✅ batch 409, 当前写出 215 行，累计 1329335 行\n",
      "✅ batch 410, 当前写出 4000 行，累计 1333335 行\n",
      "✅ batch 411, 当前写出 4000 行，累计 1337335 行\n",
      "✅ batch 412, 当前写出 4000 行，累计 1341335 行\n",
      "✅ batch 413, 当前写出 4000 行，累计 1345335 行\n",
      "✅ batch 414, 当前写出 213 行，累计 1345548 行\n",
      "✅ batch 415, 当前写出 4000 行，累计 1349548 行\n",
      "✅ batch 416, 当前写出 4000 行，累计 1353548 行\n",
      "✅ batch 417, 当前写出 4000 行，累计 1357548 行\n",
      "✅ batch 418, 当前写出 4000 行，累计 1361548 行\n",
      "✅ batch 419, 当前写出 216 行，累计 1361764 行\n",
      "✅ batch 420, 当前写出 4000 行，累计 1365764 行\n",
      "✅ batch 421, 当前写出 4000 行，累计 1369764 行\n",
      "✅ batch 422, 当前写出 4000 行，累计 1373764 行\n",
      "✅ batch 423, 当前写出 4000 行，累计 1377764 行\n",
      "✅ batch 424, 当前写出 214 行，累计 1377978 行\n",
      "✅ batch 425, 当前写出 4000 行，累计 1381978 行\n",
      "✅ batch 426, 当前写出 4000 行，累计 1385978 行\n",
      "✅ batch 427, 当前写出 4000 行，累计 1389978 行\n",
      "✅ batch 428, 当前写出 4000 行，累计 1393978 行\n",
      "✅ batch 429, 当前写出 215 行，累计 1394193 行\n",
      "✅ batch 430, 当前写出 4000 行，累计 1398193 行\n",
      "✅ batch 431, 当前写出 4000 行，累计 1402193 行\n",
      "✅ batch 432, 当前写出 4000 行，累计 1406193 行\n",
      "✅ batch 433, 当前写出 4000 行，累计 1410193 行\n",
      "✅ batch 434, 当前写出 212 行，累计 1410405 行\n",
      "✅ batch 435, 当前写出 4000 行，累计 1414405 行\n",
      "✅ batch 436, 当前写出 4000 行，累计 1418405 行\n",
      "✅ batch 437, 当前写出 4000 行，累计 1422405 行\n",
      "✅ batch 438, 当前写出 4000 行，累计 1426405 行\n",
      "✅ batch 439, 当前写出 210 行，累计 1426615 行\n",
      "✅ batch 440, 当前写出 4000 行，累计 1430615 行\n",
      "✅ batch 441, 当前写出 4000 行，累计 1434615 行\n",
      "✅ batch 442, 当前写出 4000 行，累计 1438615 行\n",
      "✅ batch 443, 当前写出 4000 行，累计 1442615 行\n",
      "✅ batch 444, 当前写出 206 行，累计 1442821 行\n",
      "✅ batch 445, 当前写出 4000 行，累计 1446821 行\n",
      "✅ batch 446, 当前写出 4000 行，累计 1450821 行\n",
      "✅ batch 447, 当前写出 4000 行，累计 1454821 行\n",
      "✅ batch 448, 当前写出 4000 行，累计 1458821 行\n",
      "✅ batch 449, 当前写出 206 行，累计 1459027 行\n",
      "✅ batch 450, 当前写出 4000 行，累计 1463027 行\n",
      "✅ batch 451, 当前写出 4000 行，累计 1467027 行\n",
      "✅ batch 452, 当前写出 4000 行，累计 1471027 行\n",
      "✅ batch 453, 当前写出 4000 行，累计 1475027 行\n",
      "✅ batch 454, 当前写出 206 行，累计 1475233 行\n",
      "✅ batch 455, 当前写出 4000 行，累计 1479233 行\n",
      "✅ batch 456, 当前写出 4000 行，累计 1483233 行\n",
      "✅ batch 457, 当前写出 4000 行，累计 1487233 行\n",
      "✅ batch 458, 当前写出 4000 行，累计 1491233 行\n",
      "✅ batch 459, 当前写出 205 行，累计 1491438 行\n",
      "✅ batch 460, 当前写出 4000 行，累计 1495438 行\n",
      "✅ batch 461, 当前写出 4000 行，累计 1499438 行\n",
      "✅ batch 462, 当前写出 4000 行，累计 1503438 行\n",
      "✅ batch 463, 当前写出 4000 行，累计 1507438 行\n",
      "✅ batch 464, 当前写出 205 行，累计 1507643 行\n",
      "✅ batch 465, 当前写出 4000 行，累计 1511643 行\n",
      "✅ batch 466, 当前写出 4000 行，累计 1515643 行\n",
      "✅ batch 467, 当前写出 4000 行，累计 1519643 行\n",
      "✅ batch 468, 当前写出 4000 行，累计 1523643 行\n",
      "✅ batch 469, 当前写出 204 行，累计 1523847 行\n",
      "✅ batch 470, 当前写出 4000 行，累计 1527847 行\n",
      "✅ batch 471, 当前写出 4000 行，累计 1531847 行\n",
      "✅ batch 472, 当前写出 4000 行，累计 1535847 行\n",
      "✅ batch 473, 当前写出 4000 行，累计 1539847 行\n",
      "✅ batch 474, 当前写出 205 行，累计 1540052 行\n",
      "✅ batch 475, 当前写出 4000 行，累计 1544052 行\n",
      "✅ batch 476, 当前写出 4000 行，累计 1548052 行\n",
      "✅ batch 477, 当前写出 4000 行，累计 1552052 行\n",
      "✅ batch 478, 当前写出 4000 行，累计 1556052 行\n",
      "✅ batch 479, 当前写出 211 行，累计 1556263 行\n",
      "✅ batch 480, 当前写出 4000 行，累计 1560263 行\n",
      "✅ batch 481, 当前写出 4000 行，累计 1564263 行\n",
      "✅ batch 482, 当前写出 4000 行，累计 1568263 行\n",
      "✅ batch 483, 当前写出 4000 行，累计 1572263 行\n",
      "✅ batch 484, 当前写出 210 行，累计 1572473 行\n",
      "✅ batch 485, 当前写出 4000 行，累计 1576473 行\n",
      "✅ batch 486, 当前写出 4000 行，累计 1580473 行\n",
      "✅ batch 487, 当前写出 4000 行，累计 1584473 行\n",
      "✅ batch 488, 当前写出 4000 行，累计 1588473 行\n",
      "✅ batch 489, 当前写出 211 行，累计 1588684 行\n",
      "✅ batch 490, 当前写出 4000 行，累计 1592684 行\n",
      "✅ batch 491, 当前写出 4000 行，累计 1596684 行\n",
      "✅ batch 492, 当前写出 4000 行，累计 1600684 行\n",
      "✅ batch 493, 当前写出 4000 行，累计 1604684 行\n",
      "✅ batch 494, 当前写出 213 行，累计 1604897 行\n",
      "✅ batch 495, 当前写出 4000 行，累计 1608897 行\n",
      "✅ batch 496, 当前写出 4000 行，累计 1612897 行\n",
      "✅ batch 497, 当前写出 4000 行，累计 1616897 行\n",
      "✅ batch 498, 当前写出 4000 行，累计 1620897 行\n",
      "✅ batch 499, 当前写出 208 行，累计 1621105 行\n",
      "✅ batch 500, 当前写出 4000 行，累计 1625105 行\n",
      "✅ batch 501, 当前写出 4000 行，累计 1629105 行\n",
      "✅ batch 502, 当前写出 4000 行，累计 1633105 行\n",
      "✅ batch 503, 当前写出 4000 行，累计 1637105 行\n",
      "✅ batch 504, 当前写出 208 行，累计 1637313 行\n",
      "✅ batch 505, 当前写出 4000 行，累计 1641313 行\n",
      "✅ batch 506, 当前写出 4000 行，累计 1645313 行\n",
      "✅ batch 507, 当前写出 4000 行，累计 1649313 行\n",
      "✅ batch 508, 当前写出 4000 行，累计 1653313 行\n",
      "✅ batch 509, 当前写出 209 行，累计 1653522 行\n",
      "✅ batch 510, 当前写出 4000 行，累计 1657522 行\n",
      "✅ batch 511, 当前写出 4000 行，累计 1661522 行\n",
      "✅ batch 512, 当前写出 4000 行，累计 1665522 行\n",
      "✅ batch 513, 当前写出 4000 行，累计 1669522 行\n",
      "✅ batch 514, 当前写出 207 行，累计 1669729 行\n",
      "✅ batch 515, 当前写出 4000 行，累计 1673729 行\n",
      "✅ batch 516, 当前写出 4000 行，累计 1677729 行\n",
      "✅ batch 517, 当前写出 4000 行，累计 1681729 行\n",
      "✅ batch 518, 当前写出 4000 行，累计 1685729 行\n",
      "✅ batch 519, 当前写出 208 行，累计 1685937 行\n",
      "✅ batch 520, 当前写出 4000 行，累计 1689937 行\n",
      "✅ batch 521, 当前写出 4000 行，累计 1693937 行\n",
      "✅ batch 522, 当前写出 4000 行，累计 1697937 行\n",
      "✅ batch 523, 当前写出 4000 行，累计 1701937 行\n",
      "✅ batch 524, 当前写出 211 行，累计 1702148 行\n",
      "✅ batch 525, 当前写出 4000 行，累计 1706148 行\n",
      "✅ batch 526, 当前写出 4000 行，累计 1710148 行\n",
      "✅ batch 527, 当前写出 4000 行，累计 1714148 行\n",
      "✅ batch 528, 当前写出 4000 行，累计 1718148 行\n",
      "✅ batch 529, 当前写出 213 行，累计 1718361 行\n",
      "✅ batch 530, 当前写出 4000 行，累计 1722361 行\n",
      "✅ batch 531, 当前写出 4000 行，累计 1726361 行\n",
      "✅ batch 532, 当前写出 4000 行，累计 1730361 行\n",
      "✅ batch 533, 当前写出 4000 行，累计 1734361 行\n",
      "✅ batch 534, 当前写出 212 行，累计 1734573 行\n",
      "✅ batch 535, 当前写出 4000 行，累计 1738573 行\n",
      "✅ batch 536, 当前写出 4000 行，累计 1742573 行\n",
      "✅ batch 537, 当前写出 4000 行，累计 1746573 行\n",
      "✅ batch 538, 当前写出 4000 行，累计 1750573 行\n",
      "✅ batch 539, 当前写出 211 行，累计 1750784 行\n",
      "✅ batch 540, 当前写出 4000 行，累计 1754784 行\n",
      "✅ batch 541, 当前写出 4000 行，累计 1758784 行\n",
      "✅ batch 542, 当前写出 4000 行，累计 1762784 行\n",
      "✅ batch 543, 当前写出 4000 行，累计 1766784 行\n",
      "✅ batch 544, 当前写出 210 行，累计 1766994 行\n",
      "✅ batch 545, 当前写出 4000 行，累计 1770994 行\n",
      "✅ batch 546, 当前写出 4000 行，累计 1774994 行\n",
      "✅ batch 547, 当前写出 4000 行，累计 1778994 行\n",
      "✅ batch 548, 当前写出 4000 行，累计 1782994 行\n",
      "✅ batch 549, 当前写出 209 行，累计 1783203 行\n",
      "✅ batch 550, 当前写出 4000 行，累计 1787203 行\n",
      "✅ batch 551, 当前写出 4000 行，累计 1791203 行\n",
      "✅ batch 552, 当前写出 4000 行，累计 1795203 行\n",
      "✅ batch 553, 当前写出 4000 行，累计 1799203 行\n",
      "✅ batch 554, 当前写出 210 行，累计 1799413 行\n",
      "✅ batch 555, 当前写出 4000 行，累计 1803413 行\n",
      "✅ batch 556, 当前写出 4000 行，累计 1807413 行\n",
      "✅ batch 557, 当前写出 4000 行，累计 1811413 行\n",
      "✅ batch 558, 当前写出 4000 行，累计 1815413 行\n",
      "✅ batch 559, 当前写出 209 行，累计 1815622 行\n",
      "✅ batch 560, 当前写出 4000 行，累计 1819622 行\n",
      "✅ batch 561, 当前写出 4000 行，累计 1823622 行\n",
      "✅ batch 562, 当前写出 4000 行，累计 1827622 行\n",
      "✅ batch 563, 当前写出 4000 行，累计 1831622 行\n",
      "✅ batch 564, 当前写出 209 行，累计 1831831 行\n",
      "✅ batch 565, 当前写出 4000 行，累计 1835831 行\n",
      "✅ batch 566, 当前写出 4000 行，累计 1839831 行\n",
      "✅ batch 567, 当前写出 4000 行，累计 1843831 行\n",
      "✅ batch 568, 当前写出 4000 行，累计 1847831 行\n",
      "✅ batch 569, 当前写出 210 行，累计 1848041 行\n",
      "✅ batch 570, 当前写出 4000 行，累计 1852041 行\n",
      "✅ batch 571, 当前写出 4000 行，累计 1856041 行\n",
      "✅ batch 572, 当前写出 4000 行，累计 1860041 行\n",
      "✅ batch 573, 当前写出 4000 行，累计 1864041 行\n",
      "✅ batch 574, 当前写出 211 行，累计 1864252 行\n",
      "✅ batch 575, 当前写出 4000 行，累计 1868252 行\n",
      "✅ batch 576, 当前写出 4000 行，累计 1872252 行\n",
      "✅ batch 577, 当前写出 4000 行，累计 1876252 行\n",
      "✅ batch 578, 当前写出 4000 行，累计 1880252 行\n",
      "✅ batch 579, 当前写出 211 行，累计 1880463 行\n",
      "✅ batch 580, 当前写出 4000 行，累计 1884463 行\n",
      "✅ batch 581, 当前写出 4000 行，累计 1888463 行\n",
      "✅ batch 582, 当前写出 4000 行，累计 1892463 行\n",
      "✅ batch 583, 当前写出 4000 行，累计 1896463 行\n",
      "✅ batch 584, 当前写出 213 行，累计 1896676 行\n",
      "✅ batch 585, 当前写出 4000 行，累计 1900676 行\n",
      "✅ batch 586, 当前写出 4000 行，累计 1904676 行\n",
      "✅ batch 587, 当前写出 4000 行，累计 1908676 行\n",
      "✅ batch 588, 当前写出 4000 行，累计 1912676 行\n",
      "✅ batch 589, 当前写出 211 行，累计 1912887 行\n",
      "✅ batch 590, 当前写出 4000 行，累计 1916887 行\n",
      "✅ batch 591, 当前写出 4000 行，累计 1920887 行\n",
      "✅ batch 592, 当前写出 4000 行，累计 1924887 行\n",
      "✅ batch 593, 当前写出 4000 行，累计 1928887 行\n",
      "✅ batch 594, 当前写出 208 行，累计 1929095 行\n",
      "✅ batch 595, 当前写出 4000 行，累计 1933095 行\n",
      "✅ batch 596, 当前写出 4000 行，累计 1937095 行\n",
      "✅ batch 597, 当前写出 4000 行，累计 1941095 行\n",
      "✅ batch 598, 当前写出 4000 行，累计 1945095 行\n",
      "✅ batch 599, 当前写出 209 行，累计 1945304 行\n",
      "✅ batch 600, 当前写出 4000 行，累计 1949304 行\n",
      "✅ batch 601, 当前写出 4000 行，累计 1953304 行\n",
      "✅ batch 602, 当前写出 4000 行，累计 1957304 行\n",
      "✅ batch 603, 当前写出 4000 行，累计 1961304 行\n",
      "✅ batch 604, 当前写出 211 行，累计 1961515 行\n",
      "✅ batch 605, 当前写出 4000 行，累计 1965515 行\n",
      "✅ batch 606, 当前写出 4000 行，累计 1969515 行\n",
      "✅ batch 607, 当前写出 4000 行，累计 1973515 行\n",
      "✅ batch 608, 当前写出 4000 行，累计 1977515 行\n",
      "✅ batch 609, 当前写出 212 行，累计 1977727 行\n",
      "✅ batch 610, 当前写出 4000 行，累计 1981727 行\n",
      "✅ batch 611, 当前写出 4000 行，累计 1985727 行\n",
      "✅ batch 612, 当前写出 4000 行，累计 1989727 行\n",
      "✅ batch 613, 当前写出 4000 行，累计 1993727 行\n",
      "✅ batch 614, 当前写出 211 行，累计 1993938 行\n",
      "✅ batch 615, 当前写出 4000 行，累计 1997938 行\n",
      "✅ batch 616, 当前写出 4000 行，累计 2001938 行\n",
      "✅ batch 617, 当前写出 4000 行，累计 2005938 行\n",
      "✅ batch 618, 当前写出 4000 行，累计 2009938 行\n",
      "✅ batch 619, 当前写出 210 行，累计 2010148 行\n",
      "✅ batch 620, 当前写出 4000 行，累计 2014148 行\n",
      "✅ batch 621, 当前写出 4000 行，累计 2018148 行\n",
      "✅ batch 622, 当前写出 4000 行，累计 2022148 行\n",
      "✅ batch 623, 当前写出 4000 行，累计 2026148 行\n",
      "✅ batch 624, 当前写出 212 行，累计 2026360 行\n",
      "✅ batch 625, 当前写出 4000 行，累计 2030360 行\n",
      "✅ batch 626, 当前写出 4000 行，累计 2034360 行\n",
      "✅ batch 627, 当前写出 4000 行，累计 2038360 行\n",
      "✅ batch 628, 当前写出 4000 行，累计 2042360 行\n",
      "✅ batch 629, 当前写出 215 行，累计 2042575 行\n",
      "✅ batch 630, 当前写出 4000 行，累计 2046575 行\n",
      "✅ batch 631, 当前写出 4000 行，累计 2050575 行\n",
      "✅ batch 632, 当前写出 4000 行，累计 2054575 行\n",
      "✅ batch 633, 当前写出 4000 行，累计 2058575 行\n",
      "✅ batch 634, 当前写出 217 行，累计 2058792 行\n",
      "✅ batch 635, 当前写出 4000 行，累计 2062792 行\n",
      "✅ batch 636, 当前写出 4000 行，累计 2066792 行\n",
      "✅ batch 637, 当前写出 4000 行，累计 2070792 行\n",
      "✅ batch 638, 当前写出 4000 行，累计 2074792 行\n",
      "✅ batch 639, 当前写出 217 行，累计 2075009 行\n",
      "✅ batch 640, 当前写出 4000 行，累计 2079009 行\n",
      "✅ batch 641, 当前写出 4000 行，累计 2083009 行\n",
      "✅ batch 642, 当前写出 4000 行，累计 2087009 行\n",
      "✅ batch 643, 当前写出 4000 行，累计 2091009 行\n",
      "✅ batch 644, 当前写出 218 行，累计 2091227 行\n",
      "✅ batch 645, 当前写出 4000 行，累计 2095227 行\n",
      "✅ batch 646, 当前写出 4000 行，累计 2099227 行\n",
      "✅ batch 647, 当前写出 4000 行，累计 2103227 行\n",
      "✅ batch 648, 当前写出 4000 行，累计 2107227 行\n",
      "✅ batch 649, 当前写出 214 行，累计 2107441 行\n",
      "✅ batch 650, 当前写出 4000 行，累计 2111441 行\n",
      "✅ batch 651, 当前写出 4000 行，累计 2115441 行\n",
      "✅ batch 652, 当前写出 4000 行，累计 2119441 行\n",
      "✅ batch 653, 当前写出 4000 行，累计 2123441 行\n",
      "✅ batch 654, 当前写出 214 行，累计 2123655 行\n",
      "✅ batch 655, 当前写出 4000 行，累计 2127655 行\n",
      "✅ batch 656, 当前写出 4000 行，累计 2131655 行\n",
      "✅ batch 657, 当前写出 4000 行，累计 2135655 行\n",
      "✅ batch 658, 当前写出 4000 行，累计 2139655 行\n",
      "✅ batch 659, 当前写出 214 行，累计 2139869 行\n",
      "✅ batch 660, 当前写出 4000 行，累计 2143869 行\n",
      "✅ batch 661, 当前写出 4000 行，累计 2147869 行\n",
      "✅ batch 662, 当前写出 4000 行，累计 2151869 行\n",
      "✅ batch 663, 当前写出 4000 行，累计 2155869 行\n",
      "✅ batch 664, 当前写出 214 行，累计 2156083 行\n",
      "✅ batch 665, 当前写出 4000 行，累计 2160083 行\n",
      "✅ batch 666, 当前写出 4000 行，累计 2164083 行\n",
      "✅ batch 667, 当前写出 4000 行，累计 2168083 行\n",
      "✅ batch 668, 当前写出 4000 行，累计 2172083 行\n",
      "✅ batch 669, 当前写出 214 行，累计 2172297 行\n",
      "✅ batch 670, 当前写出 4000 行，累计 2176297 行\n",
      "✅ batch 671, 当前写出 4000 行，累计 2180297 行\n",
      "✅ batch 672, 当前写出 4000 行，累计 2184297 行\n",
      "✅ batch 673, 当前写出 4000 行，累计 2188297 行\n",
      "✅ batch 674, 当前写出 214 行，累计 2188511 行\n",
      "✅ batch 675, 当前写出 4000 行，累计 2192511 行\n",
      "✅ batch 676, 当前写出 4000 行，累计 2196511 行\n",
      "✅ batch 677, 当前写出 4000 行，累计 2200511 行\n",
      "✅ batch 678, 当前写出 4000 行，累计 2204511 行\n",
      "✅ batch 679, 当前写出 213 行，累计 2204724 行\n",
      "✅ batch 680, 当前写出 4000 行，累计 2208724 行\n",
      "✅ batch 681, 当前写出 4000 行，累计 2212724 行\n",
      "✅ batch 682, 当前写出 4000 行，累计 2216724 行\n",
      "✅ batch 683, 当前写出 4000 行，累计 2220724 行\n",
      "✅ batch 684, 当前写出 212 行，累计 2220936 行\n",
      "✅ batch 685, 当前写出 4000 行，累计 2224936 行\n",
      "✅ batch 686, 当前写出 4000 行，累计 2228936 行\n",
      "✅ batch 687, 当前写出 4000 行，累计 2232936 行\n",
      "✅ batch 688, 当前写出 4000 行，累计 2236936 行\n",
      "✅ batch 689, 当前写出 210 行，累计 2237146 行\n",
      "✅ batch 690, 当前写出 4000 行，累计 2241146 行\n",
      "✅ batch 691, 当前写出 4000 行，累计 2245146 行\n",
      "✅ batch 692, 当前写出 4000 行，累计 2249146 行\n",
      "✅ batch 693, 当前写出 4000 行，累计 2253146 行\n",
      "✅ batch 694, 当前写出 211 行，累计 2253357 行\n",
      "✅ batch 695, 当前写出 4000 行，累计 2257357 行\n",
      "✅ batch 696, 当前写出 4000 行，累计 2261357 行\n",
      "✅ batch 697, 当前写出 4000 行，累计 2265357 行\n",
      "✅ batch 698, 当前写出 4000 行，累计 2269357 行\n",
      "✅ batch 699, 当前写出 210 行，累计 2269567 行\n",
      "✅ batch 700, 当前写出 4000 行，累计 2273567 行\n",
      "✅ batch 701, 当前写出 4000 行，累计 2277567 行\n",
      "✅ batch 702, 当前写出 4000 行，累计 2281567 行\n",
      "✅ batch 703, 当前写出 4000 行，累计 2285567 行\n",
      "✅ batch 704, 当前写出 211 行，累计 2285778 行\n",
      "✅ batch 705, 当前写出 4000 行，累计 2289778 行\n",
      "✅ batch 706, 当前写出 4000 行，累计 2293778 行\n",
      "✅ batch 707, 当前写出 4000 行，累计 2297778 行\n",
      "✅ batch 708, 当前写出 4000 行，累计 2301778 行\n",
      "✅ batch 709, 当前写出 209 行，累计 2301987 行\n",
      "✅ batch 710, 当前写出 4000 行，累计 2305987 行\n",
      "✅ batch 711, 当前写出 4000 行，累计 2309987 行\n",
      "✅ batch 712, 当前写出 4000 行，累计 2313987 行\n",
      "✅ batch 713, 当前写出 4000 行，累计 2317987 行\n",
      "✅ batch 714, 当前写出 207 行，累计 2318194 行\n",
      "✅ batch 715, 当前写出 4000 行，累计 2322194 行\n",
      "✅ batch 716, 当前写出 4000 行，累计 2326194 行\n",
      "✅ batch 717, 当前写出 4000 行，累计 2330194 行\n",
      "✅ batch 718, 当前写出 4000 行，累计 2334194 行\n",
      "✅ batch 719, 当前写出 209 行，累计 2334403 行\n",
      "✅ batch 720, 当前写出 4000 行，累计 2338403 行\n",
      "✅ batch 721, 当前写出 4000 行，累计 2342403 行\n",
      "✅ batch 722, 当前写出 4000 行，累计 2346403 行\n",
      "✅ batch 723, 当前写出 4000 行，累计 2350403 行\n",
      "✅ batch 724, 当前写出 212 行，累计 2350615 行\n",
      "✅ batch 725, 当前写出 4000 行，累计 2354615 行\n",
      "✅ batch 726, 当前写出 4000 行，累计 2358615 行\n",
      "✅ batch 727, 当前写出 4000 行，累计 2362615 行\n",
      "✅ batch 728, 当前写出 4000 行，累计 2366615 行\n",
      "✅ batch 729, 当前写出 214 行，累计 2366829 行\n",
      "✅ batch 730, 当前写出 4000 行，累计 2370829 行\n",
      "✅ batch 731, 当前写出 4000 行，累计 2374829 行\n",
      "✅ batch 732, 当前写出 4000 行，累计 2378829 行\n",
      "✅ batch 733, 当前写出 4000 行，累计 2382829 行\n",
      "✅ batch 734, 当前写出 213 行，累计 2383042 行\n",
      "✅ batch 735, 当前写出 4000 行，累计 2387042 行\n",
      "✅ batch 736, 当前写出 4000 行，累计 2391042 行\n",
      "✅ batch 737, 当前写出 4000 行，累计 2395042 行\n",
      "✅ batch 738, 当前写出 4000 行，累计 2399042 行\n",
      "✅ batch 739, 当前写出 213 行，累计 2399255 行\n",
      "✅ batch 740, 当前写出 4000 行，累计 2403255 行\n",
      "✅ batch 741, 当前写出 4000 行，累计 2407255 行\n",
      "✅ batch 742, 当前写出 4000 行，累计 2411255 行\n",
      "✅ batch 743, 当前写出 4000 行，累计 2415255 行\n",
      "✅ batch 744, 当前写出 211 行，累计 2415466 行\n",
      "✅ batch 745, 当前写出 4000 行，累计 2419466 行\n",
      "✅ batch 746, 当前写出 4000 行，累计 2423466 行\n",
      "✅ batch 747, 当前写出 4000 行，累计 2427466 行\n",
      "✅ batch 748, 当前写出 4000 行，累计 2431466 行\n",
      "✅ batch 749, 当前写出 212 行，累计 2431678 行\n",
      "✅ batch 750, 当前写出 4000 行，累计 2435678 行\n",
      "✅ batch 751, 当前写出 4000 行，累计 2439678 行\n",
      "✅ batch 752, 当前写出 4000 行，累计 2443678 行\n",
      "✅ batch 753, 当前写出 4000 行，累计 2447678 行\n",
      "✅ batch 754, 当前写出 210 行，累计 2447888 行\n",
      "✅ batch 755, 当前写出 4000 行，累计 2451888 行\n",
      "✅ batch 756, 当前写出 4000 行，累计 2455888 行\n",
      "✅ batch 757, 当前写出 4000 行，累计 2459888 行\n",
      "✅ batch 758, 当前写出 4000 行，累计 2463888 行\n",
      "✅ batch 759, 当前写出 211 行，累计 2464099 行\n",
      "✅ batch 760, 当前写出 4000 行，累计 2468099 行\n",
      "✅ batch 761, 当前写出 4000 行，累计 2472099 行\n",
      "✅ batch 762, 当前写出 4000 行，累计 2476099 行\n",
      "✅ batch 763, 当前写出 4000 行，累计 2480099 行\n",
      "✅ batch 764, 当前写出 207 行，累计 2480306 行\n",
      "✅ batch 765, 当前写出 4000 行，累计 2484306 行\n",
      "✅ batch 766, 当前写出 4000 行，累计 2488306 行\n",
      "✅ batch 767, 当前写出 4000 行，累计 2492306 行\n",
      "✅ batch 768, 当前写出 4000 行，累计 2496306 行\n",
      "✅ batch 769, 当前写出 205 行，累计 2496511 行\n",
      "✅ batch 770, 当前写出 4000 行，累计 2500511 行\n",
      "✅ batch 771, 当前写出 4000 行，累计 2504511 行\n",
      "✅ batch 772, 当前写出 4000 行，累计 2508511 行\n",
      "✅ batch 773, 当前写出 4000 行，累计 2512511 行\n",
      "✅ batch 774, 当前写出 208 行，累计 2512719 行\n",
      "✅ batch 775, 当前写出 4000 行，累计 2516719 行\n",
      "✅ batch 776, 当前写出 4000 行，累计 2520719 行\n",
      "✅ batch 777, 当前写出 4000 行，累计 2524719 行\n",
      "✅ batch 778, 当前写出 4000 行，累计 2528719 行\n",
      "✅ batch 779, 当前写出 207 行，累计 2528926 行\n",
      "✅ batch 780, 当前写出 4000 行，累计 2532926 行\n",
      "✅ batch 781, 当前写出 4000 行，累计 2536926 行\n",
      "✅ batch 782, 当前写出 4000 行，累计 2540926 行\n",
      "✅ batch 783, 当前写出 4000 行，累计 2544926 行\n",
      "✅ batch 784, 当前写出 204 行，累计 2545130 行\n",
      "✅ batch 785, 当前写出 4000 行，累计 2549130 行\n",
      "✅ batch 786, 当前写出 4000 行，累计 2553130 行\n",
      "✅ batch 787, 当前写出 4000 行，累计 2557130 行\n",
      "✅ batch 788, 当前写出 4000 行，累计 2561130 行\n",
      "✅ batch 789, 当前写出 204 行，累计 2561334 行\n",
      "✅ batch 790, 当前写出 4000 行，累计 2565334 行\n",
      "✅ batch 791, 当前写出 4000 行，累计 2569334 行\n",
      "✅ batch 792, 当前写出 4000 行，累计 2573334 行\n",
      "✅ batch 793, 当前写出 4000 行，累计 2577334 行\n",
      "✅ batch 794, 当前写出 207 行，累计 2577541 行\n",
      "✅ batch 795, 当前写出 4000 行，累计 2581541 行\n",
      "✅ batch 796, 当前写出 4000 行，累计 2585541 行\n",
      "✅ batch 797, 当前写出 4000 行，累计 2589541 行\n",
      "✅ batch 798, 当前写出 4000 行，累计 2593541 行\n",
      "✅ batch 799, 当前写出 208 行，累计 2593749 行\n",
      "✅ batch 800, 当前写出 4000 行，累计 2597749 行\n",
      "✅ batch 801, 当前写出 4000 行，累计 2601749 行\n",
      "✅ batch 802, 当前写出 4000 行，累计 2605749 行\n",
      "✅ batch 803, 当前写出 4000 行，累计 2609749 行\n",
      "✅ batch 804, 当前写出 210 行，累计 2609959 行\n",
      "✅ batch 805, 当前写出 4000 行，累计 2613959 行\n",
      "✅ batch 806, 当前写出 4000 行，累计 2617959 行\n",
      "✅ batch 807, 当前写出 4000 行，累计 2621959 行\n",
      "✅ batch 808, 当前写出 4000 行，累计 2625959 行\n",
      "✅ batch 809, 当前写出 215 行，累计 2626174 行\n",
      "✅ batch 810, 当前写出 4000 行，累计 2630174 行\n",
      "✅ batch 811, 当前写出 4000 行，累计 2634174 行\n",
      "✅ batch 812, 当前写出 4000 行，累计 2638174 行\n",
      "✅ batch 813, 当前写出 4000 行，累计 2642174 行\n",
      "✅ batch 814, 当前写出 210 行，累计 2642384 行\n",
      "✅ batch 815, 当前写出 4000 行，累计 2646384 行\n",
      "✅ batch 816, 当前写出 4000 行，累计 2650384 行\n",
      "✅ batch 817, 当前写出 4000 行，累计 2654384 行\n",
      "✅ batch 818, 当前写出 4000 行，累计 2658384 行\n",
      "✅ batch 819, 当前写出 212 行，累计 2658596 行\n",
      "✅ batch 820, 当前写出 4000 行，累计 2662596 行\n",
      "✅ batch 821, 当前写出 4000 行，累计 2666596 行\n",
      "✅ batch 822, 当前写出 4000 行，累计 2670596 行\n",
      "✅ batch 823, 当前写出 4000 行，累计 2674596 行\n",
      "✅ batch 824, 当前写出 211 行，累计 2674807 行\n",
      "✅ batch 825, 当前写出 4000 行，累计 2678807 行\n",
      "✅ batch 826, 当前写出 4000 行，累计 2682807 行\n",
      "✅ batch 827, 当前写出 4000 行，累计 2686807 行\n",
      "✅ batch 828, 当前写出 4000 行，累计 2690807 行\n",
      "✅ batch 829, 当前写出 210 行，累计 2691017 行\n",
      "✅ batch 830, 当前写出 4000 行，累计 2695017 行\n",
      "✅ batch 831, 当前写出 4000 行，累计 2699017 行\n",
      "✅ batch 832, 当前写出 4000 行，累计 2703017 行\n",
      "✅ batch 833, 当前写出 4000 行，累计 2707017 行\n",
      "✅ batch 834, 当前写出 209 行，累计 2707226 行\n",
      "✅ batch 835, 当前写出 4000 行，累计 2711226 行\n",
      "✅ batch 836, 当前写出 4000 行，累计 2715226 行\n",
      "✅ batch 837, 当前写出 4000 行，累计 2719226 行\n",
      "✅ batch 838, 当前写出 4000 行，累计 2723226 行\n",
      "✅ batch 839, 当前写出 210 行，累计 2723436 行\n",
      "✅ batch 840, 当前写出 4000 行，累计 2727436 行\n",
      "✅ batch 841, 当前写出 4000 行，累计 2731436 行\n",
      "✅ batch 842, 当前写出 4000 行，累计 2735436 行\n",
      "✅ batch 843, 当前写出 4000 行，累计 2739436 行\n",
      "✅ batch 844, 当前写出 207 行，累计 2739643 行\n",
      "✅ batch 845, 当前写出 4000 行，累计 2743643 行\n",
      "✅ batch 846, 当前写出 4000 行，累计 2747643 行\n",
      "✅ batch 847, 当前写出 4000 行，累计 2751643 行\n",
      "✅ batch 848, 当前写出 4000 行，累计 2755643 行\n",
      "✅ batch 849, 当前写出 207 行，累计 2755850 行\n",
      "✅ batch 850, 当前写出 4000 行，累计 2759850 行\n",
      "✅ batch 851, 当前写出 4000 行，累计 2763850 行\n",
      "✅ batch 852, 当前写出 4000 行，累计 2767850 行\n",
      "✅ batch 853, 当前写出 4000 行，累计 2771850 行\n",
      "✅ batch 854, 当前写出 208 行，累计 2772058 行\n",
      "✅ batch 855, 当前写出 4000 行，累计 2776058 行\n",
      "✅ batch 856, 当前写出 4000 行，累计 2780058 行\n",
      "✅ batch 857, 当前写出 4000 行，累计 2784058 行\n",
      "✅ batch 858, 当前写出 4000 行，累计 2788058 行\n",
      "✅ batch 859, 当前写出 206 行，累计 2788264 行\n",
      "✅ batch 860, 当前写出 4000 行，累计 2792264 行\n",
      "✅ batch 861, 当前写出 4000 行，累计 2796264 行\n",
      "✅ batch 862, 当前写出 4000 行，累计 2800264 行\n",
      "✅ batch 863, 当前写出 4000 行，累计 2804264 行\n",
      "✅ batch 864, 当前写出 209 行，累计 2804473 行\n",
      "✅ batch 865, 当前写出 4000 行，累计 2808473 行\n",
      "✅ batch 866, 当前写出 4000 行，累计 2812473 行\n",
      "✅ batch 867, 当前写出 4000 行，累计 2816473 行\n",
      "✅ batch 868, 当前写出 4000 行，累计 2820473 行\n",
      "✅ batch 869, 当前写出 209 行，累计 2820682 行\n",
      "✅ batch 870, 当前写出 4000 行，累计 2824682 行\n",
      "✅ batch 871, 当前写出 4000 行，累计 2828682 行\n",
      "✅ batch 872, 当前写出 4000 行，累计 2832682 行\n",
      "✅ batch 873, 当前写出 4000 行，累计 2836682 行\n",
      "✅ batch 874, 当前写出 212 行，累计 2836894 行\n",
      "✅ batch 875, 当前写出 4000 行，累计 2840894 行\n",
      "✅ batch 876, 当前写出 4000 行，累计 2844894 行\n",
      "✅ batch 877, 当前写出 4000 行，累计 2848894 行\n",
      "✅ batch 878, 当前写出 4000 行，累计 2852894 行\n",
      "✅ batch 879, 当前写出 210 行，累计 2853104 行\n",
      "✅ batch 880, 当前写出 4000 行，累计 2857104 行\n",
      "✅ batch 881, 当前写出 4000 行，累计 2861104 行\n",
      "✅ batch 882, 当前写出 4000 行，累计 2865104 行\n",
      "✅ batch 883, 当前写出 4000 行，累计 2869104 行\n",
      "✅ batch 884, 当前写出 214 行，累计 2869318 行\n",
      "✅ batch 885, 当前写出 4000 行，累计 2873318 行\n",
      "✅ batch 886, 当前写出 4000 行，累计 2877318 行\n",
      "✅ batch 887, 当前写出 4000 行，累计 2881318 行\n",
      "✅ batch 888, 当前写出 4000 行，累计 2885318 行\n",
      "✅ batch 889, 当前写出 211 行，累计 2885529 行\n",
      "✅ batch 890, 当前写出 4000 行，累计 2889529 行\n",
      "✅ batch 891, 当前写出 4000 行，累计 2893529 行\n",
      "✅ batch 892, 当前写出 4000 行，累计 2897529 行\n",
      "✅ batch 893, 当前写出 4000 行，累计 2901529 行\n",
      "✅ batch 894, 当前写出 210 行，累计 2901739 行\n",
      "✅ batch 895, 当前写出 4000 行，累计 2905739 行\n",
      "✅ batch 896, 当前写出 4000 行，累计 2909739 行\n",
      "✅ batch 897, 当前写出 4000 行，累计 2913739 行\n",
      "✅ batch 898, 当前写出 4000 行，累计 2917739 行\n",
      "✅ batch 899, 当前写出 209 行，累计 2917948 行\n",
      "✅ batch 900, 当前写出 4000 行，累计 2921948 行\n",
      "✅ batch 901, 当前写出 4000 行，累计 2925948 行\n",
      "✅ batch 902, 当前写出 4000 行，累计 2929948 行\n",
      "✅ batch 903, 当前写出 4000 行，累计 2933948 行\n",
      "✅ batch 904, 当前写出 209 行，累计 2934157 行\n",
      "✅ batch 905, 当前写出 4000 行，累计 2938157 行\n",
      "✅ batch 906, 当前写出 4000 行，累计 2942157 行\n",
      "✅ batch 907, 当前写出 4000 行，累计 2946157 行\n",
      "✅ batch 908, 当前写出 4000 行，累计 2950157 行\n",
      "✅ batch 909, 当前写出 209 行，累计 2950366 行\n",
      "✅ batch 910, 当前写出 4000 行，累计 2954366 行\n",
      "✅ batch 911, 当前写出 4000 行，累计 2958366 行\n",
      "✅ batch 912, 当前写出 4000 行，累计 2962366 行\n",
      "✅ batch 913, 当前写出 4000 行，累计 2966366 行\n",
      "✅ batch 914, 当前写出 213 行，累计 2966579 行\n",
      "✅ batch 915, 当前写出 4000 行，累计 2970579 行\n",
      "✅ batch 916, 当前写出 4000 行，累计 2974579 行\n",
      "✅ batch 917, 当前写出 4000 行，累计 2978579 行\n",
      "✅ batch 918, 当前写出 4000 行，累计 2982579 行\n",
      "✅ batch 919, 当前写出 215 行，累计 2982794 行\n",
      "✅ batch 920, 当前写出 4000 行，累计 2986794 行\n",
      "✅ batch 921, 当前写出 4000 行，累计 2990794 行\n",
      "✅ batch 922, 当前写出 4000 行，累计 2994794 行\n",
      "✅ batch 923, 当前写出 4000 行，累计 2998794 行\n",
      "✅ batch 924, 当前写出 215 行，累计 2999009 行\n",
      "✅ batch 925, 当前写出 4000 行，累计 3003009 行\n",
      "✅ batch 926, 当前写出 4000 行，累计 3007009 行\n",
      "✅ batch 927, 当前写出 4000 行，累计 3011009 行\n",
      "✅ batch 928, 当前写出 4000 行，累计 3015009 行\n",
      "✅ batch 929, 当前写出 218 行，累计 3015227 行\n",
      "✅ batch 930, 当前写出 4000 行，累计 3019227 行\n",
      "✅ batch 931, 当前写出 4000 行，累计 3023227 行\n",
      "✅ batch 932, 当前写出 4000 行，累计 3027227 行\n",
      "✅ batch 933, 当前写出 4000 行，累计 3031227 行\n",
      "✅ batch 934, 当前写出 220 行，累计 3031447 行\n",
      "✅ batch 935, 当前写出 4000 行，累计 3035447 行\n",
      "✅ batch 936, 当前写出 4000 行，累计 3039447 行\n",
      "✅ batch 937, 当前写出 4000 行，累计 3043447 行\n",
      "✅ batch 938, 当前写出 4000 行，累计 3047447 行\n",
      "✅ batch 939, 当前写出 221 行，累计 3047668 行\n",
      "✅ batch 940, 当前写出 4000 行，累计 3051668 行\n",
      "✅ batch 941, 当前写出 4000 行，累计 3055668 行\n",
      "✅ batch 942, 当前写出 4000 行，累计 3059668 行\n",
      "✅ batch 943, 当前写出 4000 行，累计 3063668 行\n",
      "✅ batch 944, 当前写出 224 行，累计 3063892 行\n",
      "✅ batch 945, 当前写出 4000 行，累计 3067892 行\n",
      "✅ batch 946, 当前写出 4000 行，累计 3071892 行\n",
      "✅ batch 947, 当前写出 4000 行，累计 3075892 行\n",
      "✅ batch 948, 当前写出 4000 行，累计 3079892 行\n",
      "✅ batch 949, 当前写出 226 行，累计 3080118 行\n",
      "✅ batch 950, 当前写出 4000 行，累计 3084118 行\n",
      "✅ batch 951, 当前写出 4000 行，累计 3088118 行\n",
      "✅ batch 952, 当前写出 4000 行，累计 3092118 行\n",
      "✅ batch 953, 当前写出 4000 行，累计 3096118 行\n",
      "✅ batch 954, 当前写出 225 行，累计 3096343 行\n",
      "✅ batch 955, 当前写出 4000 行，累计 3100343 行\n",
      "✅ batch 956, 当前写出 4000 行，累计 3104343 行\n",
      "✅ batch 957, 当前写出 4000 行，累计 3108343 行\n",
      "✅ batch 958, 当前写出 4000 行，累计 3112343 行\n",
      "✅ batch 959, 当前写出 222 行，累计 3112565 行\n",
      "✅ batch 960, 当前写出 4000 行，累计 3116565 行\n",
      "✅ batch 961, 当前写出 4000 行，累计 3120565 行\n",
      "✅ batch 962, 当前写出 4000 行，累计 3124565 行\n",
      "✅ batch 963, 当前写出 4000 行，累计 3128565 行\n",
      "✅ batch 964, 当前写出 221 行，累计 3128786 行\n",
      "✅ batch 965, 当前写出 4000 行，累计 3132786 行\n",
      "✅ batch 966, 当前写出 4000 行，累计 3136786 行\n",
      "✅ batch 967, 当前写出 4000 行，累计 3140786 行\n",
      "✅ batch 968, 当前写出 4000 行，累计 3144786 行\n",
      "✅ batch 969, 当前写出 220 行，累计 3145006 行\n",
      "✅ batch 970, 当前写出 4000 行，累计 3149006 行\n",
      "✅ batch 971, 当前写出 4000 行，累计 3153006 行\n",
      "✅ batch 972, 当前写出 4000 行，累计 3157006 行\n",
      "✅ batch 973, 当前写出 4000 行，累计 3161006 行\n",
      "✅ batch 974, 当前写出 221 行，累计 3161227 行\n",
      "✅ batch 975, 当前写出 4000 行，累计 3165227 行\n",
      "✅ batch 976, 当前写出 4000 行，累计 3169227 行\n",
      "✅ batch 977, 当前写出 4000 行，累计 3173227 行\n",
      "✅ batch 978, 当前写出 4000 行，累计 3177227 行\n",
      "✅ batch 979, 当前写出 221 行，累计 3177448 行\n",
      "✅ batch 980, 当前写出 4000 行，累计 3181448 行\n",
      "✅ batch 981, 当前写出 4000 行，累计 3185448 行\n",
      "✅ batch 982, 当前写出 4000 行，累计 3189448 行\n",
      "✅ batch 983, 当前写出 4000 行，累计 3193448 行\n",
      "✅ batch 984, 当前写出 224 行，累计 3193672 行\n",
      "✅ batch 985, 当前写出 4000 行，累计 3197672 行\n",
      "✅ batch 986, 当前写出 4000 行，累计 3201672 行\n",
      "✅ batch 987, 当前写出 4000 行，累计 3205672 行\n",
      "✅ batch 988, 当前写出 4000 行，累计 3209672 行\n",
      "✅ batch 989, 当前写出 227 行，累计 3209899 行\n",
      "✅ batch 990, 当前写出 4000 行，累计 3213899 行\n",
      "✅ batch 991, 当前写出 4000 行，累计 3217899 行\n",
      "✅ batch 992, 当前写出 4000 行，累计 3221899 行\n",
      "✅ batch 993, 当前写出 4000 行，累计 3225899 行\n",
      "✅ batch 994, 当前写出 226 行，累计 3226125 行\n",
      "✅ batch 995, 当前写出 4000 行，累计 3230125 行\n",
      "✅ batch 996, 当前写出 4000 行，累计 3234125 行\n",
      "✅ batch 997, 当前写出 4000 行，累计 3238125 行\n",
      "✅ batch 998, 当前写出 4000 行，累计 3242125 行\n",
      "✅ batch 999, 当前写出 226 行，累计 3242351 行\n",
      "🎉 Sentiment SAMPLE 写完: D:\\Columbia\\Fall2025\\5400\\project\\layer\\sentiment_sample\n",
      "实际处理行数: 3242351\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T21:24:56.161431Z",
     "start_time": "2025-11-26T21:24:56.137948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, pyarrow.parquet as pq\n",
    "\n",
    "SENTIMENT_SAMPLE = r\"D:\\Columbia\\Fall2025\\5400\\project\\layer\\sentiment_sample\"\n",
    "files = sorted(os.listdir(SENTIMENT_SAMPLE))\n",
    "print(\"文件数:\", len(files))\n",
    "print(\"示例文件:\", files[:5])\n",
    "\n",
    "t = pq.read_table(os.path.join(SENTIMENT_SAMPLE, files[0]))\n",
    "print(\"sample 一些行：\")\n",
    "print(t.to_pandas().head())\n"
   ],
   "id": "5dff7f932bdb252c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件数: 1000\n",
      "示例文件: ['part-00000.parquet', 'part-00001.parquet', 'part-00002.parquet', 'part-00003.parquet', 'part-00004.parquet']\n",
      "sample 一些行：\n",
      "         news_id sentiment_label  sentiment_score  sentiment_score_signed\n",
      "0  2284922605296        POSITIVE         0.885818                0.885818\n",
      "1  1967095022423        POSITIVE         0.999705                0.999705\n",
      "2  2422361556929        NEGATIVE         0.984156               -0.984156\n",
      "3  2181843394301        POSITIVE         0.989560                0.989560\n",
      "4  1451698949482        POSITIVE         0.990559                0.990559\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T21:26:45.668722Z",
     "start_time": "2025-11-26T21:25:28.501602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# join_sentiment_silver_sample.py\n",
    "import os\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "\n",
    "def create_spark(app_name=\"5400-news-elt-join-sample\"):\n",
    "    spark = (\n",
    "        SparkSession.builder\n",
    "        .appName(app_name)\n",
    "        .master(\"local[*]\")\n",
    "        .config(\"spark.driver.memory\", \"12g\")\n",
    "        .config(\"spark.executor.memory\", \"12g\")\n",
    "        .config(\"spark.sql.shuffle.partitions\", \"400\")\n",
    "        .config(\"spark.default.parallelism\", \"400\")\n",
    "        .config(\"spark.sql.parquet.compression.codec\", \"snappy\")\n",
    "        .getOrCreate()\n",
    "    )\n",
    "    spark.sparkContext.setLogLevel(\"WARN\")\n",
    "    return spark\n",
    "\n",
    "BASE = r\"D:\\Columbia\\Fall2025\\5400\\project\\layer\"\n",
    "SILVER = os.path.join(BASE, \"silver\")\n",
    "SENTIMENT_SAMPLE = os.path.join(BASE, \"sentiment_sample\")\n",
    "SILVER_WITH_SENT_SAMPLE = os.path.join(BASE, \"silver_with_sentiment_sample\")\n",
    "\n",
    "spark = create_spark()\n",
    "\n",
    "silver_df = spark.read.parquet(SILVER)\n",
    "sent_df = spark.read.parquet(SENTIMENT_SAMPLE)\n",
    "\n",
    "print(\"银层行数：\", silver_df.count())\n",
    "print(\"情感样本行数：\", sent_df.count())\n",
    "\n",
    "# left join\n",
    "silver_with_sent = silver_df.join(sent_df, on=\"news_id\", how=\"left\")\n",
    "\n",
    "silver_with_sent = silver_with_sent.repartition(200, \"Stock_symbol\", \"Date\")\n",
    "\n",
    "(\n",
    "    silver_with_sent\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .parquet(SILVER_WITH_SENT_SAMPLE)\n",
    ")\n",
    "\n",
    "print(\"✅ silver_with_sentiment_sample 写入完成：\", SILVER_WITH_SENT_SAMPLE)\n",
    "\n",
    "test_df = spark.read.parquet(SILVER_WITH_SENT_SAMPLE)\n",
    "test_df.select(\"news_id\",\"Article_title\",\"sentiment_label\",\n",
    "               \"sentiment_score_signed\").show(20, False)\n",
    "\n",
    "spark.stop()\n"
   ],
   "id": "26e3be506f48d579",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "银层行数： 3242351\n",
      "情感样本行数： 3242351\n",
      "✅ silver_with_sentiment_sample 写入完成： D:\\Columbia\\Fall2025\\5400\\project\\layer\\silver_with_sentiment_sample\n",
      "+-------------+----------------------------------------------------------------------------------------------------------------------------------+---------------+----------------------+\n",
      "|news_id      |Article_title                                                                                                                     |sentiment_label|sentiment_score_signed|\n",
      "+-------------+----------------------------------------------------------------------------------------------------------------------------------+---------------+----------------------+\n",
      "|317827582759 |Benzinga's Top Upgrades, Downgrades For July 1, 2019                                                                              |NEGATIVE       |-0.990228533744812    |\n",
      "|386547061560 |Are Hedge Funds Setup For A Short Squeeze?                                                                                        |NEGATIVE       |-0.9980898499488831   |\n",
      "|498216209968 |Eli Lilly Reports on SGLT-2 Trials                                                                                                |NEGATIVE       |-0.9258176684379578   |\n",
      "|575525623482 |Stocks That Managed to Breach 52-Week Highs Wednesday Morning                                                                     |NEGATIVE       |-0.9952006340026855   |\n",
      "|979252548560 |PBF Logistics' (PBFX) CEO Tom Nimbley on Q1 2016 Results - Earnings Call Transcript                                               |NEGATIVE       |-0.9646628499031067   |\n",
      "|1082331766042|TICC Capital: Dividend Stress Test                                                                                                |NEGATIVE       |-0.9960005879402161   |\n",
      "|1099511630247|China: This Party Is Dying                                                                                                        |NEGATIVE       |-0.9996291399002075   |\n",
      "|1211180781577|The Zacks Analyst Blog Highlights: Alpha Natural Resources, Patriot Coal, CSX, Norfolk Southern and Union Pacific - Press Releases|POSITIVE       |0.9812049865722656    |\n",
      "|1219770713247|Political Brinkmanship                                                                                                            |NEGATIVE       |-0.9688841700553894   |\n",
      "|1245540522189|Industrial metals surge as Trump-Xi truce eases fears                                                                             |NEGATIVE       |-0.7766788005828857   |\n",
      "|1305670060653|Option Alert: WLL 7/29 8.5 Calls (Wkly) Sweep: 1676 @ ASK $0.25: 12k traded vs 6087 OI: Earnings today After Close $8.06 Ref      |NEGATIVE       |-0.9913219809532166   |\n",
      "|1305670061580|SBA to buy Brazilian towers                                                                                                       |NEGATIVE       |-0.5782272815704346   |\n",
      "|1443109012647|A O Smith Sees FY2015 EPS $2.65-2.80 vs $2.76 Est; Sees Sales $2.60B vs $2.56B Est                                                |NEGATIVE       |-0.9943917393684387   |\n",
      "|1443109017071|Public Employees Retirement Association Of Colorado Buys Treehouse Foods Inc, American Tower ...                                  |NEGATIVE       |-0.980633556842804    |\n",
      "|1460288882650|Benzinga's Top Initiations                                                                                                        |POSITIVE       |0.9919111132621765    |\n",
      "|1503238554002|Maxim Capital Management LLC Buys Vanguard Total International Bond ETF, iShares –-' Year ...                                     |NEGATIVE       |-0.875665545463562    |\n",
      "|1511828488268|Juno Therapeutics (JUNO) Leaps AsxDrug Trials Resume                                                                              |NEGATIVE       |-0.9913572072982788   |\n",
      "|1589137904919|Global Wearable Sensors Market Estimated to be Valued at USD –,94'.6 Million by —…—4                                              |NEGATIVE       |-0.9676199555397034   |\n",
      "|1717986922679|Dividend Champion And Contender Highlights: Week Of August 25                                                                     |POSITIVE       |0.9613692164421082    |\n",
      "|1717986926324|US Stock Futures Down, H-P Shares Drop In Pre-Market                                                                              |NEGATIVE       |-0.9972257018089294   |\n",
      "+-------------+----------------------------------------------------------------------------------------------------------------------------------+---------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T21:35:59.621896Z",
     "start_time": "2025-11-26T21:35:32.291256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "\n",
    "def create_spark(app_name=\"5400-news-gold-sent\"):\n",
    "    spark = (\n",
    "        SparkSession.builder\n",
    "        .appName(app_name)\n",
    "        .master(\"local[*]\")\n",
    "        .config(\"spark.driver.memory\", \"12g\")\n",
    "        .config(\"spark.executor.memory\", \"12g\")\n",
    "        .config(\"spark.sql.shuffle.partitions\", \"400\")\n",
    "        .config(\"spark.default.parallelism\", \"400\")\n",
    "        .config(\"spark.sql.parquet.compression.codec\", \"snappy\")\n",
    "        .getOrCreate()\n",
    "    )\n",
    "    spark.sparkContext.setLogLevel(\"WARN\")\n",
    "    return spark\n",
    "\n",
    "BASE = r\"D:\\Columbia\\Fall2025\\5400\\project\\layer\"\n",
    "SILVER_WITH_SENT_SAMPLE = os.path.join(BASE, \"silver_with_sentiment_sample\")\n",
    "GOLD = os.path.join(BASE, \"gold\")\n",
    "GOLD_WITH_SENT = os.path.join(BASE, \"gold_with_sentiment\")\n",
    "\n",
    "spark = create_spark()\n",
    "\n",
    "silver_sent = spark.read.parquet(SILVER_WITH_SENT_SAMPLE)\n",
    "gold_df = spark.read.parquet(GOLD)\n",
    "\n",
    "# 1. aggregate sentiment by (Date, Stock_symbol)\n",
    "sent_agg = (\n",
    "    silver_sent\n",
    "    .groupBy(\"Date\", \"Stock_symbol\")\n",
    "    .agg(\n",
    "        F.avg(\"sentiment_score_signed\").alias(\"avg_sentiment_score\"),\n",
    "        F.sum(F.when(F.col(\"sentiment_label\") == \"POSITIVE\", 1).otherwise(0)).alias(\"pos_article_count\"),\n",
    "        F.sum(F.when(F.col(\"sentiment_label\") == \"NEGATIVE\", 1).otherwise(0)).alias(\"neg_article_count\"),\n",
    "        # 这里 count(sentiment_label) 只统计有标签的文章（NULL 会被自动排除）\n",
    "        F.count(F.col(\"sentiment_label\")).alias(\"sentiment_article_count\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# 2. join with gold\n",
    "gold_with_sent = (\n",
    "    gold_df.alias(\"g\")\n",
    "    .join(\n",
    "        sent_agg.alias(\"s\"),\n",
    "        on=[\"Date\", \"Stock_symbol\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# 3. sentiment coverage\n",
    "gold_with_sent = gold_with_sent.withColumn(\n",
    "    \"sentiment_coverage\",\n",
    "    F.when(\n",
    "        F.col(\"article_count\") > 0,\n",
    "        F.col(\"sentiment_article_count\").cast(\"double\") / F.col(\"article_count\")\n",
    "    ).otherwise(F.lit(0.0))  # 没有文章 / 空值 时覆盖率设为 0\n",
    ")\n",
    "\n",
    "# 4. repartition\n",
    "gold_with_sent = gold_with_sent.repartition(200, \"Stock_symbol\")\n",
    "\n",
    "(\n",
    "    gold_with_sent\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .parquet(GOLD_WITH_SENT)\n",
    ")\n",
    "\n",
    "print(\"🏆 gold_with_sentiment 写入完成：\", GOLD_WITH_SENT)\n",
    "\n",
    "spark.stop()\n"
   ],
   "id": "2bc05eb2f19abc14",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏆 gold_with_sentiment 写入完成： D:\\Columbia\\Fall2025\\5400\\project\\layer\\gold_with_sentiment\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Final Gold NLP\n",
   "id": "b133c0f1e3c761d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T21:37:21.347258Z",
     "start_time": "2025-11-26T21:36:55.228354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# gold_with_sentiment_sample.py\n",
    "import os\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "\n",
    "def create_spark(app_name=\"5400-news-gold-sent-sample\"):\n",
    "    spark = (\n",
    "        SparkSession.builder\n",
    "        .appName(app_name)\n",
    "        .master(\"local[*]\")\n",
    "        .config(\"spark.driver.memory\", \"12g\")\n",
    "        .config(\"spark.executor.memory\", \"12g\")\n",
    "        .config(\"spark.sql.shuffle.partitions\", \"400\")\n",
    "        .config(\"spark.default.parallelism\", \"400\")\n",
    "        .config(\"spark.sql.parquet.compression.codec\", \"snappy\")\n",
    "        .getOrCreate()\n",
    "    )\n",
    "    spark.sparkContext.setLogLevel(\"WARN\")\n",
    "    return spark\n",
    "\n",
    "# ============================\n",
    "# path\n",
    "# ============================\n",
    "\n",
    "BASE = r\"D:\\Columbia\\Fall2025\\5400\\project\\layer\"\n",
    "\n",
    "GOLD = os.path.join(BASE, \"gold\")   # 原 gold（无情感）\n",
    "SILVER_WITH_SENT_SAMPLE = os.path.join(BASE, \"silver_with_sentiment_sample\")\n",
    "GOLD_WITH_SENT_SAMPLE = os.path.join(BASE, \"gold_with_sentiment_sample\")\n",
    "\n",
    "spark = create_spark()\n",
    "\n",
    "# ============================\n",
    "# read data\n",
    "# ============================\n",
    "gold_df = spark.read.parquet(GOLD)\n",
    "silver_sent = spark.read.parquet(SILVER_WITH_SENT_SAMPLE)\n",
    "\n",
    "print(\"Gold 行数（原聚合）:\", gold_df.count())\n",
    "print(\"Silver + Sentiment sample 行数:\", silver_sent.count())\n",
    "\n",
    "# ============================\n",
    "# 1) aggregate sentiment by (Date, Stock_symbol)\n",
    "# ============================\n",
    "\n",
    "sent_agg = (\n",
    "    silver_sent\n",
    "    .groupBy(\"Date\", \"Stock_symbol\")\n",
    "    .agg(\n",
    "        F.avg(\"sentiment_score_signed\").alias(\"avg_sentiment_score\"),\n",
    "        F.sum(F.when(F.col(\"sentiment_label\") == \"POSITIVE\", 1).otherwise(0)).alias(\"pos_article_count\"),\n",
    "        F.sum(F.when(F.col(\"sentiment_label\") == \"NEGATIVE\", 1).otherwise(0)).alias(\"neg_article_count\"),\n",
    "        F.count(F.col(\"sentiment_label\")).alias(\"sentiment_article_count\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# ratio of pos/neg\n",
    "sent_agg = (\n",
    "    sent_agg\n",
    "    .withColumn(\n",
    "        \"pos_ratio\",\n",
    "        F.when(F.col(\"sentiment_article_count\") > 0,\n",
    "               F.col(\"pos_article_count\") / F.col(\"sentiment_article_count\"))\n",
    "         .otherwise(F.lit(None))\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"neg_ratio\",\n",
    "        F.when(F.col(\"sentiment_article_count\") > 0,\n",
    "               F.col(\"neg_article_count\") / F.col(\"sentiment_article_count\"))\n",
    "         .otherwise(F.lit(None))\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"情感聚合完成\")\n",
    "\n",
    "# ============================\n",
    "# 2) join with gold\n",
    "# ============================\n",
    "\n",
    "gold_with_sent = (\n",
    "    gold_df.alias(\"g\")\n",
    "    .join(sent_agg.alias(\"s\"), on=[\"Date\", \"Stock_symbol\"], how=\"left\")\n",
    ")\n",
    "\n",
    "# 3) sentiment category\n",
    "gold_with_sent = gold_with_sent.withColumn(\n",
    "    \"sentiment_category\",\n",
    "    F.when(F.col(\"avg_sentiment_score\") >= 0.2, \"POSITIVE\")\n",
    "     .when(F.col(\"avg_sentiment_score\") <= -0.2, \"NEGATIVE\")\n",
    "     .otherwise(\"NEUTRAL\")\n",
    ")\n",
    "\n",
    "# partition\n",
    "gold_with_sent = gold_with_sent.repartition(100, \"Stock_symbol\")\n",
    "\n",
    "(\n",
    "    gold_with_sent\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .parquet(GOLD_WITH_SENT_SAMPLE)\n",
    ")\n",
    "\n",
    "print(\"🏆 gold_with_sentiment_sample 写入完成：\", GOLD_WITH_SENT_SAMPLE)\n",
    "\n",
    "gold_with_sent.select(\n",
    "    \"Date\", \"Stock_symbol\",\n",
    "    \"article_count\", \"publisher_count\", \"avg_title_len\",\n",
    "    \"avg_sentiment_score\", \"sentiment_article_count\",\n",
    "    \"pos_ratio\", \"neg_ratio\", \"sentiment_category\"\n",
    ").show(10, False)\n",
    "\n",
    "spark.stop()\n"
   ],
   "id": "c9f631d962168f26",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold 行数（原聚合）: 1896033\n",
      "Silver + Sentiment sample 行数: 3242351\n",
      "情感聚合完成\n",
      "🏆 gold_with_sentiment_sample 写入完成： D:\\Columbia\\Fall2025\\5400\\project\\layer\\gold_with_sentiment_sample\n",
      "+----------+------------+-------------+---------------+-------------+-------------------+-----------------------+---------+---------+------------------+\n",
      "|Date      |Stock_symbol|article_count|publisher_count|avg_title_len|avg_sentiment_score|sentiment_article_count|pos_ratio|neg_ratio|sentiment_category|\n",
      "+----------+------------+-------------+---------------+-------------+-------------------+-----------------------+---------+---------+------------------+\n",
      "|2010-03-03|SGOL        |1            |1              |30.0         |0.9998376369476318 |1                      |1.0      |0.0      |POSITIVE          |\n",
      "|2010-04-06|LEN         |2            |2              |58.5         |-0.9546563923358917|2                      |0.0      |1.0      |NEGATIVE          |\n",
      "|2010-05-13|MMSI        |2            |1              |61.0         |-0.9969361424446106|2                      |0.0      |1.0      |NEGATIVE          |\n",
      "|2010-07-06|CCK         |1            |1              |58.0         |0.9998202919960022 |1                      |1.0      |0.0      |POSITIVE          |\n",
      "|2010-07-29|RUTH        |1            |1              |48.0         |-0.9996920824050903|1                      |0.0      |1.0      |NEGATIVE          |\n",
      "|2010-08-01|TYG         |1            |1              |111.0        |-0.9056552052497864|1                      |0.0      |1.0      |NEGATIVE          |\n",
      "|2010-09-26|NTES        |1            |1              |45.0         |-0.9936258792877197|1                      |0.0      |1.0      |NEGATIVE          |\n",
      "|2010-11-01|PLTM        |1            |1              |46.0         |-0.9593507647514343|1                      |0.0      |1.0      |NEGATIVE          |\n",
      "|2010-12-22|RUTH        |2            |1              |42.0         |0.9731562733650208 |2                      |1.0      |0.0      |POSITIVE          |\n",
      "|2011-01-16|CRS         |1            |1              |65.0         |0.9975680708885193 |1                      |1.0      |0.0      |POSITIVE          |\n",
      "+----------+------------+-------------+---------------+-------------+-------------------+-----------------------+---------+---------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T21:37:46.288575Z",
     "start_time": "2025-11-26T21:37:41.712992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.dataset as ds\n",
    "\n",
    "GOLD_WITH_SENT_SAMPLE = r\"D:\\Columbia\\Fall2025\\5400\\project\\layer\\gold_with_sentiment_sample\"\n",
    "OUTPUT_CSV = r\"D:\\Columbia\\Fall2025\\5400\\project\\gold_with_sentiment_sample.csv\"\n",
    "\n",
    "dataset = ds.dataset(GOLD_WITH_SENT_SAMPLE, format=\"parquet\")\n",
    "table = dataset.to_table()\n",
    "df = table.to_pandas()\n",
    "\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(\"CSV 已导出：\", OUTPUT_CSV)"
   ],
   "id": "5e3b5eca0445e6d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 已导出： D:\\Columbia\\Fall2025\\5400\\project\\gold_with_sentiment_sample.csv\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 文件名: 01_data_prep.py\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# --- 路径定义 (需保持一致) ---\n",
    "BASE = r\"D:\\Columbia\\Fall2025\\5400\\project\\layer\"\n",
    "CSV_PATH = r\"D:\\Columbia\\Fall2025\\5400\\project\\All_external.csv\"\n",
    "BRONZE = os.path.join(BASE, \"bronze\")\n",
    "SILVER = os.path.join(BASE, \"silver\")\n",
    "NLP_INPUT = os.path.join(BASE, \"silver_for_nlp\")\n",
    "\n",
    "def create_spark(app_name=\"Step1_Prep_331\"):\n",
    "    spark = (\n",
    "        SparkSession.builder\n",
    "        .appName(app_name)\n",
    "        .master(\"local[*]\")\n",
    "        .config(\"spark.driver.memory\", \"12g\")\n",
    "        .config(\"spark.executor.memory\", \"12g\")\n",
    "        .config(\"spark.sql.shuffle.partitions\", \"400\")\n",
    "        .config(\"spark.default.parallelism\", \"400\")\n",
    "        .getOrCreate()\n",
    "    )\n",
    "    spark.sparkContext.setLogLevel(\"WARN\")\n",
    "    return spark\n",
    "\n",
    "def build_bronze(spark):\n",
    "    # (省略实现，同原代码的 Bronze 逻辑)\n",
    "    if os.path.exists(BRONZE): shutil.rmtree(BRONZE)\n",
    "    df = spark.read.option(\"header\", \"true\").csv(CSV_PATH)\n",
    "    for c in df.columns: df = df.withColumn(c, F.trim(F.col(c)))\n",
    "    df = df.withColumn(\"Date\", F.to_date(F.col(\"Date\"), \"yyyy-mm-dd\"))\n",
    "    df.write.mode(\"overwrite\").parquet(BRONZE)\n",
    "    return df\n",
    "\n",
    "def build_silver(spark):\n",
    "    # (省略实现，同原代码的 Silver 逻辑)\n",
    "    if os.path.exists(SILVER): shutil.rmtree(SILVER)\n",
    "    bronze_df = spark.read.parquet(BRONZE)\n",
    "    silver_df = bronze_df.filter(F.col(\"Date\").isNotNull() & F.col(\"Stock_symbol\").isNotNull()) \\\n",
    "                         .dropDuplicates([\"Date\", \"Stock_symbol\", \"Article_title\"]) \\\n",
    "                         .withColumn(\"news_id\", F.md5(F.concat_ws(\"|\", \"Date\", \"Stock_symbol\", \"Article_title\")))\n",
    "    silver_df.write.mode(\"overwrite\").parquet(SILVER)\n",
    "    return silver_df\n",
    "\n",
    "def export_for_nlp(spark):\n",
    "    \"\"\"导出 news_id 和 text，供独立 NLP 环境使用\"\"\"\n",
    "    print(\"Step 1.3: Exporting minimal data for NLP...\")\n",
    "    if os.path.exists(NLP_INPUT): shutil.rmtree(NLP_INPUT)\n",
    "\n",
    "    silver_df = spark.read.parquet(SILVER)\n",
    "\n",
    "    nlp_df = silver_df.select(\n",
    "        \"news_id\",\n",
    "        F.concat_ws(\" . \", F.col(\"Article_title\"), F.col(\"Lsa_summary\")).alias(\"text\")\n",
    "    ).filter(\"text != ''\")\n",
    "\n",
    "    # 减少分区数，方便纯 Python 环境读取（减少文件数）\n",
    "    nlp_df.repartition(10).write.mode(\"overwrite\").parquet(NLP_INPUT)\n",
    "    print(f\"✅ Data Prep Done! NLP input ready at: {NLP_INPUT}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spark = create_spark()\n",
    "    build_bronze(spark)\n",
    "    build_silver(spark)\n",
    "    export_for_nlp(spark)\n",
    "    spark.stop()"
   ],
   "id": "19ab32d4b41c67ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a279baa992490279"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9b67af57c80d807f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 整理",
   "id": "73555b7f2b70dfe2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T04:37:52.192418Z",
     "start_time": "2025-11-28T04:37:52.181088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 1. 配置与初始化\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "# CSV 路径 (这是唯一的本地文件依赖，Spark 必须从这里读取数据源)\n",
    "CSV_PATH = r\"D:\\Columbia\\Fall2025\\5400\\project\\All_external.csv\"\n",
    "\n",
    "# Snowflake 配置\n",
    "SNOWFLAKE_CONNECTOR_PACKAGE = \"net.snowflake:spark-snowflake_2.12:2.11.0-spark_3.3\"\n",
    "SNOWFLAKE_OPTIONS = {\n",
    "    # 使用您提供的账户 ID\n",
    "    \"sfURL\": \"POBRIUX-FYC84817.snowflakecomputing.com\",\n",
    "    \"sfUser\": \"AKAAAAFK\",\n",
    "    # ⭐⭐⭐ 认证修复: 您必须在此处提供密码或私钥文件路径 ⭐⭐⭐\n",
    "    \"sfPassword\": \"<请在此处替换为您的 Snowflake 密码>\",\n",
    "    # 或者如果使用 Key-Pair 认证: \"pem_private_key\": \"/path/to/your/rsa_key.p8\"\n",
    "\n",
    "    # 使用您提供的数据库、Schema、仓库和角色\n",
    "    \"sfDatabase\": \"SNOWFLAKE_LEARNING_DB\",\n",
    "    \"sfSchema\": \"PUBLIC\",\n",
    "    \"sfWarehouse\": \"COMPUTE_WH\",\n",
    "    \"sfRole\": \"ACCOUNTADMIN\" # 增加了 Role 参数\n",
    "}\n",
    "\n",
    "# Snowflake Tables/Stage Names\n",
    "BRONZE_TABLE = \"BRONZE_NEWS\"\n",
    "SILVER_TABLE = \"SILVER_NEWS\"\n",
    "NLP_INPUT_STAGE = \"@NEWS_NLP_INPUT_STAGE\" # Snowflake 内部 Stage，用于 NLP 输入\n",
    "\n",
    "\n",
    "def create_spark(app_name=\"5400-news-elt-snowflake\"):\n",
    "    \"\"\"初始化 Spark Session 并加载 Snowflake Connector JAR\"\"\"\n",
    "    spark = (\n",
    "        SparkSession.builder\n",
    "        .appName(app_name)\n",
    "        .master(\"local[*]\")\n",
    "        .config(\"spark.driver.memory\", \"12g\")\n",
    "        .config(\"spark.executor.memory\", \"12g\")\n",
    "        .config(\"spark.sql.shuffle.partitions\", \"400\")\n",
    "        .config(\"spark.default.parallelism\", \"400\")\n",
    "        .config(\"spark.jars.packages\", SNOWFLAKE_CONNECTOR_PACKAGE)\n",
    "        .getOrCreate()\n",
    "    )\n",
    "    spark.sparkContext.setLogLevel(\"WARN\")\n",
    "    return spark\n",
    "\n",
    "\n",
    "def save_to_snowflake(df, table_name, mode=\"overwrite\", is_stage=False):\n",
    "    \"\"\"写入 Snowflake Table 或 Stage\"\"\"\n",
    "    print(f\"❄️ 正在尝试将 DataFrame 写入 Snowflake {'Stage' if is_stage else 'Table'}: {table_name}...\")\n",
    "    try:\n",
    "        writer = df.write.format(\"net.snowflake.spark.snowflake\").options(**SNOWFLAKE_OPTIONS)\n",
    "        if is_stage:\n",
    "            # 写入 Stage (Spark Connector 自动使用 COPY INTO 流程)\n",
    "            writer.option(\"dbtable\", table_name).option(\"autopurge\", \"true\").save()\n",
    "        else:\n",
    "            # 写入 Table\n",
    "            writer.option(\"dbtable\", table_name).mode(mode).save()\n",
    "\n",
    "        print(f\"✅ 数据已成功写入 Snowflake {'Stage' if is_stage else 'Table'}: {table_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Snowflake 写入失败。错误: {e}\")"
   ],
   "id": "395f4944f790c8b8",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T04:37:53.795747Z",
     "start_time": "2025-11-28T04:37:53.784367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_bronze(spark, csv_path):\n",
    "    \"\"\"读取 CSV，直接写入 BRONZE_NEWS 表\"\"\"\n",
    "    print(\"🚀 1. Building Bronze Layer...\")\n",
    "    # 保持原代码的 CSV 读取逻辑\n",
    "    df = spark.read.format(\"csv\").options(header=\"true\", inferSchema=\"true\", multiLine=\"true\", escape=\"\\\"\", quote=\"\\\"\", mode=\"PERMISSIVE\").load(csv_path)\n",
    "\n",
    "    # 基础清洗\n",
    "    for c, t in df.dtypes:\n",
    "        if t == \"string\":\n",
    "            df = df.withColumn(c, F.trim(F.col(c)))\n",
    "\n",
    "    if \"Date\" in df.columns:\n",
    "        df = df.withColumn(\"Date\", F.to_date(\"Date\", \"yyyy-MM-dd\"))\n",
    "\n",
    "    df = df.repartition(400)\n",
    "    save_to_snowflake(df, BRONZE_TABLE, mode=\"overwrite\")\n",
    "    print(\"🥉 Bronze Ready.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def build_silver(spark):\n",
    "    \"\"\"读取 BRONZE_NEWS，清洗后写入 SILVER_NEWS 表\"\"\"\n",
    "    print(\"🚀 2. Building Silver Layer...\")\n",
    "    # 从 Snowflake 读取 Bronze\n",
    "    df = spark.read.format(\"net.snowflake.spark.snowflake\").options(**SNOWFLAKE_OPTIONS).option(\"dbtable\", BRONZE_TABLE).load()\n",
    "\n",
    "    # 清洗和去重\n",
    "    if \"Date\" in df.columns: df = df.filter(F.col(\"Date\").isNotNull())\n",
    "    if \"Stock_symbol\" in df.columns: df = df.filter(F.col(\"Stock_symbol\").isNotNull())\n",
    "    df = df.dropDuplicates()\n",
    "    if \"Publisher\" in df.columns: df = df.withColumn(\"Publisher_norm\", F.upper(\"Publisher\"))\n",
    "    if \"Author\" in df.columns: df = df.withColumn(\"Author_norm\", F.upper(\"Author\"))\n",
    "    df = df.withColumn(\"news_id\", F.monotonically_increasing_id())\n",
    "    df = df.repartition(400, \"Stock_symbol\", \"Date\")\n",
    "\n",
    "    save_to_snowflake(df, SILVER_TABLE, mode=\"overwrite\")\n",
    "    print(\"🥈 Silver Ready.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def build_silver_nlp(spark):\n",
    "    \"\"\"准备 NLP 输入：合并文本源，筛选非空文本，写入 Snowflake Stage\"\"\"\n",
    "    print(\"🚀 3. Preparing Data for NLP (Writing to Snowflake Stage)...\")\n",
    "    # 从 Snowflake 读取 Silver\n",
    "    df = spark.read.format(\"net.snowflake.spark.snowflake\").options(**SNOWFLAKE_OPTIONS).option(\"dbtable\", SILVER_TABLE).load()\n",
    "\n",
    "    # 文本合并逻辑\n",
    "    df = df.withColumn(\n",
    "        \"text\",\n",
    "        F.coalesce(F.col(\"Article\"), F.col(\"Textrank_summary\"), F.col(\"Lsa_summary\"), F.col(\"Luhn_summary\"), F.col(\"Lexrank_summary\"), F.col(\"Article_title\"))\n",
    "    )\n",
    "\n",
    "    df = df.filter(F.col(\"text\").isNotNull() & (F.length(F.trim(\"text\")) > 0))\n",
    "\n",
    "    df = df.select(\"news_id\", \"text\").repartition(200)\n",
    "\n",
    "    # ⭐ 写入 Snowflake Stage\n",
    "    save_to_snowflake(df, NLP_INPUT_STAGE, is_stage=True)\n",
    "\n",
    "    print(\"🧠 Silver_for_nlp Stage 文件已生成:\", NLP_INPUT_STAGE)\n",
    "    return df"
   ],
   "id": "170339a0d0071488",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-11-28T04:37:58.044703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# -------------------------------------------------------------------------\n",
    "# 3. 主执行块\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spark = create_spark()\n",
    "\n",
    "    # 按照顺序执行所有 ETL 步骤，Silver 和 Gold 会自动写入 Snowflake\n",
    "    bronze_df = build_bronze(spark, CSV_PATH)\n",
    "    # silver_df = build_silver(spark)\n",
    "    # gold_df   = build_gold(spark)\n",
    "    # nlp_df    = build_silver_nlp(spark)\n",
    "\n",
    "    spark.stop()\n",
    "    print(\"✅ ETL 流程完成，数据已同步至 Snowflake，NLP 输入已准备就绪。\")"
   ],
   "id": "a4f6e342846f9e47",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 1. Building Bronze Layer...\n",
      "❄️ 正在尝试将 DataFrame 写入 Snowflake Table: BRONZE_NEWS...\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 文件名: etl_layers.py (已修复连接参数和认证缺失问题)\n",
    "\n",
    "import os\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 1. 配置与初始化\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "# CSV 路径 (Spark 必须读取本地文件)\n",
    "CSV_PATH = r\"D:\\Columbia\\Fall2025\\5400\\project\\All_external.csv\"\n",
    "\n",
    "# Snowflake 配置 (使用您提供的参数)\n",
    "SNOWFLAKE_CONNECTOR_PACKAGE = \"net.snowflake:spark-snowflake_2.12:2.11.0-spark_3.3\"\n",
    "SNOWFLAKE_OPTIONS = {\n",
    "    # 使用您提供的账户 ID\n",
    "    \"sfURL\": \"POBRIUX-FYC84817.snowflakecomputing.com\",\n",
    "    \"sfUser\": \"AKAAAAFK\",\n",
    "    # ⭐⭐⭐ 认证修复: 您必须在此处提供密码或私钥文件路径 ⭐⭐⭐\n",
    "    \"sfPassword\": \"<请在此处替换为您的 Snowflake 密码>\",\n",
    "    # 或者如果使用 Key-Pair 认证: \"pem_private_key\": \"/path/to/your/rsa_key.p8\"\n",
    "\n",
    "    # 使用您提供的数据库、Schema、仓库和角色\n",
    "    \"sfDatabase\": \"SNOWFLAKE_LEARNING_DB\",\n",
    "    \"sfSchema\": \"PUBLIC\",\n",
    "    \"sfWarehouse\": \"COMPUTE_WH\",\n",
    "    \"sfRole\": \"ACCOUNTADMIN\" # 增加了 Role 参数\n",
    "}\n",
    "\n",
    "# Snowflake Tables/Stage Names\n",
    "BRONZE_TABLE = \"BRONZE_NEWS\"\n",
    "SILVER_TABLE = \"SILVER_NEWS\"\n",
    "NLP_INPUT_STAGE = \"@NEWS_NLP_INPUT_STAGE\"\n",
    "\n",
    "\n",
    "def create_spark(app_name=\"5400-news-elt-snowflake\"):\n",
    "    \"\"\"初始化 Spark Session 并加载 Snowflake Connector JAR\"\"\"\n",
    "    # ... (函数体不变) ...\n",
    "    spark = (\n",
    "        SparkSession.builder\n",
    "        .appName(app_name)\n",
    "        .master(\"local[*]\")\n",
    "        .config(\"spark.driver.memory\", \"12g\")\n",
    "        .config(\"spark.executor.memory\", \"12g\")\n",
    "        .config(\"spark.sql.shuffle.partitions\", \"400\")\n",
    "        .config(\"spark.default.parallelism\", \"400\")\n",
    "        .config(\"spark.jars.packages\", SNOWFLAKE_CONNECTOR_PACKAGE)\n",
    "        .getOrCreate()\n",
    "    )\n",
    "    spark.sparkContext.setLogLevel(\"WARN\")\n",
    "    return spark\n",
    "\n",
    "\n",
    "def save_to_snowflake(df, table_name, mode=\"overwrite\", is_stage=False):\n",
    "    \"\"\"写入 Snowflake Table 或 Stage\"\"\"\n",
    "    print(f\"❄️ 正在尝试将 DataFrame 写入 Snowflake {'Stage' if is_stage else 'Table'}: {table_name}...\")\n",
    "    try:\n",
    "        writer = df.write.format(\"net.snowflake.spark.snowflake\").options(**SNOWFLAKE_OPTIONS)\n",
    "        if is_stage:\n",
    "            writer.option(\"dbtable\", table_name).option(\"autopurge\", \"true\").save()\n",
    "        else:\n",
    "            writer.option(\"dbtable\", table_name).mode(mode).save()\n",
    "\n",
    "        print(f\"✅ 数据已成功写入 Snowflake {'Stage' if is_stage else 'Table'}: {table_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Snowflake 写入失败。错误: {e}\")\n",
    "        raise # 重新抛出错误，以便您能看到详细的连接失败信息\n",
    "\n",
    "\n",
    "def build_bronze(spark, csv_path):\n",
    "    \"\"\"读取 CSV，直接写入 BRONZE_NEWS 表\"\"\"\n",
    "    print(\"🚀 1. Building Bronze Layer...\")\n",
    "    # ... (CSV 读取和基础清洗逻辑不变) ...\n",
    "    df = spark.read.format(\"csv\").options(header=\"true\", inferSchema=\"true\", multiLine=\"true\", escape=\"\\\"\", quote=\"\\\"\", mode=\"PERMISSIVE\").load(csv_path)\n",
    "\n",
    "    for c, t in df.dtypes:\n",
    "        if t == \"string\":\n",
    "            df = df.withColumn(c, F.trim(F.col(c)))\n",
    "\n",
    "    if \"Date\" in df.columns:\n",
    "        df = df.withColumn(\"Date\", F.to_date(\"Date\", \"yyyy-MM-dd\"))\n",
    "\n",
    "    df = df.repartition(400)\n",
    "    save_to_snowflake(df, BRONZE_TABLE, mode=\"overwrite\")\n",
    "    print(\"🥉 Bronze Ready.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def build_silver(spark):\n",
    "    \"\"\"读取 BRONZE_NEWS，清洗后写入 SILVER_NEWS 表\"\"\"\n",
    "    # ... (读取和清洗逻辑不变) ...\n",
    "    print(\"🚀 2. Building Silver Layer...\")\n",
    "    df = spark.read.format(\"net.snowflake.spark.snowflake\").options(**SNOWFLAKE_OPTIONS).option(\"dbtable\", BRONZE_TABLE).load()\n",
    "\n",
    "    if \"Date\" in df.columns: df = df.filter(F.col(\"Date\").isNotNull())\n",
    "    if \"Stock_symbol\" in df.columns: df = df.filter(F.col(\"Stock_symbol\").isNotNull())\n",
    "    df = df.dropDuplicates()\n",
    "    if \"Publisher\" in df.columns: df = df.withColumn(\"Publisher_norm\", F.upper(\"Publisher\"))\n",
    "    if \"Author\" in df.columns: df = df.withColumn(\"Author_norm\", F.upper(\"Author\"))\n",
    "    df = df.withColumn(\"news_id\", F.monotonically_increasing_id())\n",
    "    df = df.repartition(400, \"Stock_symbol\", \"Date\")\n",
    "\n",
    "    save_to_snowflake(df, SILVER_TABLE, mode=\"overwrite\")\n",
    "    print(\"🥈 Silver Ready.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def build_silver_nlp(spark):\n",
    "    \"\"\"准备 NLP 输入：写入 Snowflake Stage\"\"\"\n",
    "    # ... (逻辑不变) ...\n",
    "    print(\"🚀 3. Preparing Data for NLP (Writing to Snowflake Stage)...\")\n",
    "    df = spark.read.format(\"net.snowflake.spark.snowflake\").options(**SNOWFLAKE_OPTIONS).option(\"dbtable\", SILVER_TABLE).load()\n",
    "\n",
    "    df = df.withColumn(\n",
    "        \"text\",\n",
    "        F.coalesce(F.col(\"Article\"), F.col(\"Textrank_summary\"), F.col(\"Lsa_summary\"), F.col(\"Luhn_summary\"), F.col(\"Lexrank_summary\"), F.col(\"Article_title\"))\n",
    "    )\n",
    "\n",
    "    df = df.filter(F.col(\"text\").isNotNull() & (F.length(F.trim(\"text\")) > 0))\n",
    "\n",
    "    df = df.select(\"news_id\", \"text\").repartition(200)\n",
    "\n",
    "    save_to_snowflake(df, NLP_INPUT_STAGE, is_stage=True)\n",
    "\n",
    "    print(\"🧠 Silver_for_nlp Stage 文件已生成:\", NLP_INPUT_STAGE)\n",
    "    return df\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# 3. 主执行块\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spark = create_spark()\n",
    "\n",
    "    # 按照顺序执行 ETL 步骤\n",
    "    try:\n",
    "        build_bronze(spark, CSV_PATH)\n",
    "        # build_silver(spark)\n",
    "       #  build_silver_nlp(spark)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n致命错误：ETL 流程中断。请检查您的 Snowflake 凭证。\")\n",
    "\n",
    "    spark.stop()\n",
    "    print(\"✅ ETL 流程执行完毕。\")"
   ],
   "id": "31bcd38c4c53ae51"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5200643ff5c3e4d2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 文件名: nlp_inference_batch.py (独立 NLP 推理)\n",
    "# 运行环境要求: Python, pandas, pyarrow, torch, transformers (无需 PySpark)\n",
    "\n",
    "import os\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import shutil\n",
    "\n",
    "# --- 路径定义 (需保持一致) ---\n",
    "BASE = r\"D:\\Columbia\\Fall2025\\5400\\project\\layer\"\n",
    "NLP_SILVER = os.path.join(BASE, \"silver_for_nlp\") # ETL 脚本的输出\n",
    "SENTIMENT_SAMPLE = os.path.join(BASE, \"sentiment_sample\") # NLP 脚本的输出\n",
    "\n",
    "def run_nlp_inference():\n",
    "    \"\"\"执行独立、高性能的 NLP 情感分析批处理\"\"\"\n",
    "    print(\"🚀 Step 2: Starting NLP Inference (Pure Python/AI Environment)...\")\n",
    "\n",
    "    # 1. 路径准备和 GPU 检测\n",
    "    os.makedirs(SENTIMENT_SAMPLE, exist_ok=True)\n",
    "    if os.path.exists(SENTIMENT_SAMPLE): shutil.rmtree(SENTIMENT_SAMPLE)\n",
    "\n",
    "    if torch.cuda.is_available() and torch.cuda.device_count() > 0:\n",
    "        device = 0\n",
    "        print(\"✅ Using GPU device 0 for sentiment.\")\n",
    "    else:\n",
    "        device = -1\n",
    "        print(\"⚠ 没有可用 CUDA 设备，使用 CPU。\")\n",
    "\n",
    "    # 2. Hugging Face pipeline 初始化\n",
    "    try:\n",
    "        sentiment_pipe = pipeline(\n",
    "            \"sentiment-analysis\",\n",
    "            model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "            device=device,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 模型加载失败。请检查环境和网络。错误: {e}\")\n",
    "        return\n",
    "\n",
    "    # 3. 准备数据集和处理参数\n",
    "    try:\n",
    "        dataset = ds.dataset(NLP_SILVER, format=\"parquet\")\n",
    "        total_rows = dataset.count_rows()\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 无法读取 NLP 输入文件。请确保 etl_layers.py 已运行。错误: {e}\")\n",
    "        return\n",
    "\n",
    "    print(\"🧠 NLP total rows:\", total_rows)\n",
    "\n",
    "    BATCH_ROWS = 4000        # 每次从 Parquet 读取的行数\n",
    "    PIPELINE_BATCH = 32      # 模型推理的内部 batch_size\n",
    "    MAX_LENGTH = 256\n",
    "    MAX_ROWS = total_rows    # 您的原代码设置为全量\n",
    "    processed_rows = 0\n",
    "\n",
    "    batches = dataset.to_batches(batch_size=BATCH_ROWS)\n",
    "\n",
    "    # 4. 批处理循环和推理\n",
    "    for i, batch in enumerate(batches):\n",
    "        if processed_rows >= MAX_ROWS:\n",
    "            print(f\"⚡ 已达到 MAX_ROWS={MAX_ROWS}，提前结束。\")\n",
    "            break\n",
    "\n",
    "        table = pa.Table.from_batches([batch])\n",
    "        pdf = table.to_pandas()\n",
    "\n",
    "        # 只保留有 text 的行\n",
    "        pdf = pdf[pdf[\"text\"].notna() & (pdf[\"text\"].astype(str).str.strip() != \"\")]\n",
    "        if pdf.empty:\n",
    "            continue\n",
    "\n",
    "        texts = pdf[\"text\"].astype(str).tolist()\n",
    "\n",
    "        preds = sentiment_pipe(\n",
    "            texts,\n",
    "            batch_size=PIPELINE_BATCH,\n",
    "            truncation=True,\n",
    "            max_length=MAX_LENGTH,\n",
    "        )\n",
    "\n",
    "        # 整理和计算分数\n",
    "        pdf[\"sentiment_label\"] = [p[\"label\"] for p in preds]\n",
    "        pdf[\"sentiment_score\"] = [float(p[\"score\"]) for p in preds]\n",
    "        pdf[\"sentiment_score_signed\"] = pdf[\"sentiment_score\"].where(\n",
    "            pdf[\"sentiment_label\"] == \"POSITIVE\",\n",
    "            -pdf[\"sentiment_score\"],\n",
    "        )\n",
    "\n",
    "        # 写入结果 (仅保留 news_id 和分数)\n",
    "        out_pdf = pdf[[\"news_id\", \"sentiment_label\",\n",
    "                       \"sentiment_score\", \"sentiment_score_signed\"]]\n",
    "        out_table = pa.Table.from_pandas(out_pdf, preserve_index=False)\n",
    "\n",
    "        out_file = os.path.join(SENTIMENT_SAMPLE, f\"part-{i:05d}.parquet\")\n",
    "        pq.write_table(out_table, out_file)\n",
    "\n",
    "        processed_rows += len(out_pdf)\n",
    "        print(f\"✅ batch {i}, 当前写出 {len(out_pdf)} 行，累计 {processed_rows} 行\")\n",
    "\n",
    "    print(\"🎉 Sentiment SAMPLE 写完:\", SENTIMENT_SAMPLE)\n",
    "    print(\"实际处理行数:\", processed_rows)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_nlp_inference()"
   ],
   "id": "d7d1aa7a14832693"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
